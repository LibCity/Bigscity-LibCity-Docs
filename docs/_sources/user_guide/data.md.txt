# Data Introduction

本文档用于介绍数据流。

## Data Flow

- 原始数据 Raw Data

  原始的开源数据集，针对每一种支持的原始数据集，我们提供脚本以将其转化为原子文件。

- 原子文件 Atomic Files

  不同交通预测任务的基础输入元素，用于构建Dataset类。

- Dataset

  针对每一类交通预测任务制定的Dataset类，负责加载原子文件并进行一些数据预处理操作，以及切分训练集、验证集、测试集。

- DataLoader

  负责加载数据的`Dataloader`类，使用`pytorch`原生的`torch.utils.data.DataLoader`，负责将数据以`Batch`类的形式返回给模型使用。

## Raw Data

### Foursquare

### Foursquare：NYC Restaurant Rich Dataset

### Foursquare：Global-scale Check-in Dataset

### Foursquare：User Profile Dataset

### Foursquare：Global-scale Check-in Dataset with User Social Networks

### Gowalla

### Brightkite

### GeoLife-GPS

出行轨迹，基本就是user_ID，time ，lat，lon，location_id的格式



### NYC-Bus

每条数据包含当前时间，公共汽车位置（经纬度），车辆ID，已行驶距离，公共汽车路线ID，下一站ID，到该站的距离

【本质上是不同时刻的公交车位置数据集】



### NYC-Taxi

按行程ID组织数据（Per Trip），

黄色车：

上下车时间、上下车地点（经纬度）、行程距离、分项票价、费率类型、付款类型和司机报告的乘客数量

绿色车：

取车和还车时间、上下车地点（ID）、行程距离、分项票价、费率类型、付款类型和司机报告的乘客数量

FHV车：

上下车时间、上下车地点（ID）



### NYC-Bike

按行程ID组织数据（Per Trip），

旅程用时、起止时间、起止地点ID、起止地点Name、起止地点经纬度、车辆ID、用户类别、用户生日、用户性别



### BikeDC

按行程ID组织数据（Per Trip），

起止时间、起止地点ID、起止地点Name、起止地点经纬度、车辆类型、车辆ID、用户类别



### BikeCHI

按行程ID组织数据（Per Trip），

起止时间、起止地点ID、起止地点Name、起止地点经纬度、车辆类型、车辆ID、用户类别



### AustinRide

按行程ID组织数据（Per Trip），

旅程距离、起止时间、起止地点经纬度、车辆ID、用户ID等



### I-80

按车辆ID组织数据，每隔一段时间记录一次车的位置，数据的每一行是车辆ID、车辆位置坐标、车辆的相关信息、车辆瞬时速度等



### T-Drive

按车辆ID组织数据，每隔一段时间记录一次车的位置，数据的每一行是车辆ID，时间，车辆位置经纬度



### Porto

按行程ID组织数据（Per Trip），

每个Trip包含开始地点、开始时间、司机ID、一系列位置坐标：每隔一段时间记录一次车的位置（经纬度）



### TaxiBJ

四维张量： [timeslots, inflow/outflow, grid_line_id, grid_column_id]，直接给出了inflow和outflow，只适合于流量预测



### Uber

（不建议使用，没有下车的位置和时间？感觉是从NYC数据集抽取的数据集）

Uber2014：

上车时间、上车地点经纬度

Uber2015：

上车时间、上车地点ID

FLV：

上车时间、上车地点名



### METR-LA

DataFrame二维表的格式

sensor_id            400001  400017  400030  400040  400045  400052  ...  413026  413845  413877  413878  414284  414694
2017-01-01 00:00:00    71.4    67.8    70.5    67.4    68.8    66.6  ...    69.2    68.9    70.4    68.8    71.1    68.0
2017-01-01 00:05:00    71.6    67.5    70.6    67.5    68.7    66.6  ...    70.4    68.8    70.1    68.4    70.8    67.4
2017-01-01 00:10:00    71.6    67.6    70.2    67.4    68.7    66.1  ...    70.2    68.3    69.8    68.4    70.5    67.9
2017-01-01 00:15:00    71.1    67.5    70.3    68.0    68.5    66.7  ...    70.4    68.7    70.2    68.4    70.8    67.6
2017-01-01 00:20:00    71.7    67.8    70.2    68.1    68.4    66.9  ...    69.6    69.1    70.0    68.4    71.0    67.9

列是时间，间隔为5min。行是sensor编号，提供文件表示sensor的经纬度。值是速度。

用sensor之间的距离矩阵代表路网（adjacency matrix、权重矩阵、代表节点的相似度）



### Los-loop

（这个就是METR-LA）



### SZ-Taxi

DataFrame二维表的格式

列是时间，间隔为15min。行是sensor编号。值是速度。

提供adjacency matrix描述路网的结构（1或0，邻接与否）



### Loop Seattle

`df = pd.read_pickle('speed_matrix_2015')`

DataFrame二维表的格式

ID                   d005es15036  d005es15125  d005es15214  ...  i520es00861  i520es00935  i520es00972
stamp                                                       ...
2015-01-01 00:00:00    61.939138    64.280883    62.077397  ...    68.112571    66.567829    62.032062
2015-01-01 00:05:00    59.232527    65.082450    64.808345  ...    59.022999    58.949034    61.212069
2015-01-01 00:10:00    61.991801    65.309123    64.803916  ...    58.710086    56.671427    57.488732
2015-01-01 00:15:00    62.480655    65.191651    67.206597  ...    64.368119    57.892398    64.087189
2015-01-01 00:20:00    62.490484    65.287669    67.323285  ...    62.795588    62.545365    64.567285

列是时间，间隔为5min。行是sensor编号。值是速度。

提供adjacency matrix描述路网的结构（1或0，邻接与否）



### NYC Speed data

按照道路ID组织数据，每一条数据包括道路ID、速度、时间、穿过道路的平均用时。

对于每个道路，提供文件描述一系列道路上sensor的经纬度位置、道路名称等。

Sequence of Lat/ Long points, describes locations of the sensor links



### HK

按照道路ID组织数据，每一条数据包括道路ID、道路区域、道路类型、道路状况等级、速度、时间。

时间间隔较短，可以得到每条道路，各个时间的速度信息。

对于每个路段link，提供文件描述起始站、终点站、以及相应的经纬度、道路类型。(基于它们可以构建路网的拓扑)



### Q-Traffic

：query sub-dataset

每条数据包括起始时间、起点经纬度、终点经纬度、预计的旅行时间

：traffic speed sub-dataset

数据收集的间隔为15min，每条数据为路段ID，时间戳 ([0, 5856))，速度(km/h)。

：road network sub-dataset

对于每个路段link，提供路段的起点（节点）和终点（节点），基于它们可以构建路网的拓扑、提供宽度，长度km，方向，限速和车道数信息。提供一个经纬度，不知道是起点还是终点。



### ENG-HW

每个站点不同时间的流量数据



### PEMS

### PeMSD3

DataFrame二维表的格式

列是时间，间隔为5min。行是sensor编号。值是flow。

也提供的numpy三维张量，时间间隔5min，三维（时间戳，sensor编号，flow）

用sensor之间的距离矩阵代表路网（adjacency matrix）



### PeMSD4

提供的numpy三维张量，时间间隔5min，三维（时间戳，sensor编号，（flow, occupy, speed））

用sensor之间的距离矩阵代表路网（adjacency matrix）



### PEMSD7

提供的numpy三维张量，时间间隔5min，三维（时间戳，sensor编号，flow）

用sensor之间的距离矩阵代表路网（adjacency matrix）



### PeMSD8

提供的numpy三维张量，时间间隔5min，三维（时间戳，sensor编号，（flow, occupy, speed））

用sensor之间的距离矩阵代表路网（adjacency matrix）



### PEMSD7(M){#index}

DataFrame二维表的格式

列是时间，间隔为5min。行是sensor编号。值是速度。

用sensor之间的距离矩阵代表路网（adjacency matrix）



### PeMSD-SF

Occupancy



### PEMS-BAY

DataFrame二维表的格式

​                                       773869     767541     767542     717447  ...     717595     772168     718141  769373

2012-03-01 00:00:00  64.375000  67.625000  67.125000  61.500000  ...  69.000000  59.250000  69.000000  61.875
2012-03-01 00:05:00  62.666667  68.555556  65.444444  62.444444  ...  64.444444  55.888889  68.444444  62.875
2012-03-01 00:10:00  64.000000  63.750000  60.000000  59.000000  ...  65.625000  61.375000  69.857143  62.000
2012-03-01 00:15:00   0.000000   0.000000   0.000000   0.000000  ...   0.000000   0.000000   0.000000   0.000
2012-03-01 00:20:00   0.000000   0.000000   0.000000   0.000000  ...   0.000000   0.000000   0.000000   0.000

列是时间，间隔为5min。行是sensor编号，提供文件表示sensor的经纬度。值是速度。

用sensor之间的距离矩阵代表路网（adjacency matrix、权重矩阵、代表节点的相似度）



### BusCHI

交通拥堵状况数据集



### NYC Accident data

发生碰撞的日期、时间、经纬度、街道名、受伤人数、死亡人数、原因、车辆类型等



### Road network data (OpenStreetMap)

https://www.openstreetmap.org/



### Weather and events data

https://www.wunderground.com/



### External data

常见的外部数据项。

- 气象条件：温度、湿度、风速、能见度和天气状态（晴/雨/风/多云等）
- 驾驶员ID：由于驾驶员的个人情况不同，预测会有一定的影响，因此有必要对驾驶员进行标记，此信息主要用于个人预测。
- 活动：包括各种节假日、交通管制、交通事故、体育赛事、音乐会等活动。
- 时间信息：星期几，一天中的时间片。

## Atomic Files

定义如下几种原子文件：

| 文件名      | 内容                                     | 示例                                          |
| ----------- | ---------------------------------------- | --------------------------------------------- |
| xxx.geo     | 存储地理实体属性信息。                   | geo_id, type, coordinates                     |
| xxx.usr     | 存储交通使用者信息。                     | usr_id, gender, birth_date                    |
| xxx.rel     | 存储实体间的关系信息，如路网或社交网络。 | rel_id, origin_id,   destination_id           |
| xxx.dyna    | 存储实体随时间动态变化的信息，如轨迹。   | dyna_id, type, time,   entity_id, location_id |
| config.json | 用于补充描述各表信息。                   |                                               |

对于不同的交通预测任务，可能用到不同的原子文件；一个数据集不一定包含全部5种原子文件。

### Geo 表

Geo 表中一个元素由以下四部分组成：geo_id, type, coordinates, properties。

1. geo_id: int 类。主键，唯一确定一个 geo 实体。

2. type：枚举类，表示该 geo 的类型。一共有 “Point”、“LineString”、“Polygon” 三个值。此三值与 geojson 中的点线面一致。

3. coordinates：由 float 组成的数组或嵌套数组。描述 geo 实体的位置信息，采用 geojson 的 coordinates 格式。转换成 csv 时，整个数组加上双引号即可“”。

4. properties：键值字典。描述该 geo 的属性信息，如 "POI_name", "POI_type"。转换成 csv 时，将 properties 下的键作为列名即可。（保证对于同一 type 的 properties 具有相同的键）

### Usr 表

Usr 表中一个元素由以下两部分组成：usr_id, properties。

1. usr_id：int 类。主键，唯一确定一个 usr 实体。

2. properties：键值字典。描述该 usr 实体的属性信息，如 "gender", "birth_date"。转换成 csv 时，将 properties 下的键作为列名即可。

### Rel 表

Rel 表中一个元素由以下四个部分组成：rel_id, type, origin_id, destination_id, properties。

1. rel_id：int 类。主键，唯一确定一个实体间的关系。

2. type：枚举类。一共有两种取值 "usr"，"geo"。表示该关系是基于 geo 的还是基于 usr 的。

3. origin_id：int 类，关系起点方的 ID，为 Geo 表或 Usr 表中的一个，并通过 config 文件指定是哪一张表中的关系。

4. destination_id：int 类，关系终点方的 ID，具体细节同 origin_id。

5. properties：键值字典，描述该关系所具有的属性信息，如 "link_weight"。该 properties 可能为空。

### Dyna 表

Dyna 表中一个元素由以下五部分组成：dyna_id, type, time, entity_id, properties。

1. dyna_id：int 类。主键，唯一标识动态表中的一条记录。

2. type：枚举类，一共有三种取值 "trajectory"、"od"、"state"。

3. time：string 类。时间信息。对于非 "od"，采用 ISO-8601 标准中的日期和时间的组合表示法，如："2020-12-07T02:59:46Z"。对于 "od"，因为要记录起终两个时间，可以将两个时间点仍以前述的格式表示，然后二者中间加空格拼接成一个新的字符串的形式进行存储。

4. entity_id：int 类。描述该记录是基于哪一个实体观测产生的。

5. properties：键值字典。描述该记录额外的属性信息。对于 "trajectory"，properties 应至少包含位置信息（经纬度或 geo_id）；对于 "od"，properties 应至少包含 od 的 id；对于 "state"，properties 至少包含具体交通状态信息。 

Dyna表必须含有的 properties 键

| od    | trajectory | state |
| ----- | ---------- | ----- |
| od_id | location   | 无    |

### 数据类型定义

需要在 config 文件中给出数据集中各列的数据类型定义，有助于后续的数据处理。

| 类型       | 说明                                  |
| ---------- | ------------------------------------- |
| geo_id     | 存在于 geo 表中的离散的有限的 ID      |
| usr_id     | 存在于 usr 表中的离散的有限的 ID      |
| rel_id     | 存在于 rel 表中的离散的有限的 ID      |
| time       | 符合 ISO-8601 标准的时间字符串        |
| coordinate | 符合 geojosn 格式的坐标表示法的字符串 |
| num        | 实数类                                |
| enum       | 枚举类字符串                          |
| other      | 其余的均以字符串类型存储              |

### Config 文件

 Config 文件用以补充描述上述四个表自身的信息，即各个表的 properties 字段具体含有的哪些属性。以 json 的格式存储，且由 geo、usr、rel、dyna 四个键组成。

1. geo, rel, dyna：首先包含一个 including_types 的键，以数组的形式描述该表中所具有的 type 值。其后每个 type 作为键，描述该 type 下 properties 具有哪些键以及其数据类型（dyna 表需要额外把 entity_id 也加以说明）。

2. usr：包含一个 properties 键，描述表中 properties 包含哪些键以及其数据类型。

样例如下：

```json
{
    "geo":{
        "including_types":[
            "Point"
        ],
        "PointProperties":{
            "poi_name":"geo_id",
            "poi_type":"enum"
        }
    },
    "usr":{
        "properties":{
            "user_type":"enum",
            "birth_year":"time",
            "gender":"enum"
        }
    },
    "rel":{
        "including_types":[
            "geo"
        ],
        "geo":{
            "link_weight":"num"
        }
    },
    "dyna":{
        "including_types":[
            "trajectory",
            "od",
            "state"
        ],
        "trajectory":{
            "entity_id":"usr_id",
            "location":"geo_id",
            "twitter_text":"other"
        },
        "od":{
            "entity_id":"usr_id",
            "od_id":"rel_id",
            "trip_duration":"num"
        },
        "state":{
            "entity_id":"geo_id",
            "traffic_speed":"num"
        }
    }
}
```

## Batch

`Batch`是由`DataLoader`加载并输入到预测模型中的内部数据结构。

从`Dataloader`中取出的对象都是`Batch`类的对象。

`Batch`类是基于`python.dict`实现的抽象数据类型，其构成`key-value`的结构，其中`key`是模型输入的特征名，`value`是对应特征的张量（`torch.Tensor`），其包含一个batch或mini-batch的全部相关的张量数据。

所以可以使用如下的方式来获取相应的value：

```python
loc = batch['current_loc']
tim = batch['current_tim']
```

`value`基于`torch.Tensor`实现，在`Batch`类中我们实现了对数据的长度补齐操作、原始数据转Tensor等一系列常用函数。

## Args for Data

记录数据集涉及的相关参数