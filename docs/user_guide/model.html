

<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Reproduced Model List &mdash; Bigscity-LibCity  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=b3ba4146"></script>
      <script src="../_static/doctools.js?v=888ff710"></script>
      <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Evaluator Introduction" href="evaluator.html" />
    <link rel="prev" title="Dataset For Task" href="data/dataset_for_task.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Bigscity-LibCity
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../get_started/introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started/install.html">Install LibCity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started/quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started/directory_structure.html">Directory Structure</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="config_settings.html">Config Settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">Data Introduction</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Reproduced Model List</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#baselines">Baselines</a></li>
<li class="toctree-l2"><a class="reference internal" href="#traffic-flow-prediction">Traffic Flow Prediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#traffic-speed-prediction">Traffic Speed Prediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#on-demand-service-prediction">On-Demand Service Prediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#origin-destination-matrix-prediction">Origin-Destination Matrix Prediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#traffic-accidents-prediction">Traffic Accidents Prediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#trajectory-next-location-prediction">Trajectory Next-Location Prediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#estimated-time-of-arrival">Estimated Time of Arrival</a></li>
<li class="toctree-l2"><a class="reference internal" href="#map-matching">Map Matching</a></li>
<li class="toctree-l2"><a class="reference internal" href="#road-network-representation-learning">Road Network Representation Learning</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="evaluator.html">Evaluator Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="executor.html">Executor Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage.html">Usage</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../developer_guide/code_style.html">Code Style</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer_guide/implemented_datasets.html">Customize Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer_guide/implemented_models.html">Customize Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer_guide/implemented_executors.html">Customize Executors</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorial</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorial/install_quick_start.html">Install and quick start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial/run_model.html">Run an existing model in LibCity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial/add_model.html">Add a new model to LibCity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial/hyper_tune.html">Tuning the model with automatic tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial/data_visualization.html">Visualize Atomic Files</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API REFERENCE</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../libcity/libcity.config.html">libcity.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../libcity/libcity.data.html">libcity.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../libcity/libcity.evaluator.html">libcity.evaluator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../libcity/libcity.executor.html">libcity.executor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../libcity/libcity.model.html">libcity.model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../libcity/libcity.pipeline.html">libcity.pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../libcity/libcity.utils.html">libcity.utils</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Bigscity-LibCity</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Reproduced Model List</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/user_guide/model.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="reproduced-model-list">
<h1>Reproduced Model List<a class="headerlink" href="#reproduced-model-list" title="Permalink to this heading"></a></h1>
<section id="baselines">
<h2>Baselines<a class="headerlink" href="#baselines" title="Permalink to this heading"></a></h2>
<p>For time series prediction: (model code is in test/)</p>
<ul>
<li><p><strong>HA</strong>:</p>
<p>Historical Average, which models the historical traffic as a seasonal process, then uses weighted average of previous seasons as predicted values.</p>
</li>
<li><p><strong>VAR</strong>:</p>
<p>Vector Auto-Regression, which is a commonly used model for time series forecasting to capture the relationship of multiple variables over time.</p>
</li>
<li><p><strong>SVR</strong>:</p>
<p>Support Vector Regression which uses linear support vector machine for the regression task. SVR uses historical data to train the model to establish the relationship between input and output, and then make predictions.</p>
</li>
<li><p><strong>ARIMA</strong></p>
<p>Auto-Regressive Integrated Moving Average model with Kalman filter.</p>
</li>
</ul>
<p>For traffic flow/speed/demand prediction:</p>
<ul>
<li><p><strong>AutoEncoder</strong>:</p>
<p>This baseline model is implemented by ourselves, which uses an encoder to learn an embedded vector from data and then use a decoder to predict the future traffic state.</p>
</li>
<li><p><strong>RNN(FC-RNN)</strong>:</p>
<p>This baseline model is implemented by ourselves for traffic state prediction task based on RNN.</p>
</li>
<li><p><strong>Seq2Seq</strong>:</p>
<p>This baseline model is implemented by ourselves for traffic state prediction task based on Encoder-Decoder structure. We utilize the encode-decoder framework based on gated recurrent unit for multi-step prediction.</p>
</li>
<li><p><strong>FNN</strong>：</p>
<p>This baseline model is implemented by ourselves for traffic state prediction task based on Feed forward neural network with two hidden layers and L2 regularization.</p>
</li>
</ul>
<p>For trajectory next-location prediction:</p>
<ul>
<li><p><strong>RNN</strong>:</p>
<p>This baseline model is implemented by ourselves with RNN.</p>
</li>
</ul>
</section>
<section id="traffic-flow-prediction">
<h2>Traffic Flow Prediction<a class="headerlink" href="#traffic-flow-prediction" title="Permalink to this heading"></a></h2>
<ul>
<li><p><strong>ST-ResNet</strong>:</p>
<p>Spatio-Temporal Residual Networks, which is widely used in grid-based flow prediction task and models the spatio-temporal correlations by residual unit.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Junbo Zhang, Yu Zheng, and Dekang Qi. 2017. Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction. In AAAI. AAAI Press, 1655–1661.
</pre></div>
</div>
</li>
<li><p><strong>ACFM</strong>:</p>
<p>Attentive Crowd Flow Machines, which is able to infer the evolution of the crowd flow by learning dynamic representations of temporally-varying data with an attention mechanism.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Lingbo Liu, Ruimao Zhang, Jiefeng Peng, Guanbin Li, Bowen Du, and Liang Lin. 2018. Attentive Crowd Flow Machines. In MM. ACM, 1553–1561.
</pre></div>
</div>
</li>
<li><p><strong>STNN</strong>:</p>
<p>STNN learns these dependencies through a structured latent dynamical component, while a decoder predicts the observations from the latent representations.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Ali</span> <span class="n">Ziat</span><span class="p">,</span> <span class="n">Edouard</span> <span class="n">Delasalles</span><span class="p">,</span> <span class="n">Ludovic</span> <span class="n">Denoyer</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Patrick</span> <span class="n">Gallinari</span><span class="o">.</span> <span class="mf">2018.</span> <span class="n">Spatio</span><span class="o">-</span><span class="n">Temporal</span> <span class="n">Neural</span> <span class="n">Networks</span> <span class="k">for</span> <span class="n">Space</span><span class="o">-</span><span class="n">Time</span> <span class="n">Series</span> <span class="n">Forecasting</span> <span class="ow">and</span> <span class="n">Relations</span> <span class="n">Discovery</span><span class="o">.</span> <span class="n">In</span> <span class="n">ICDM</span><span class="o">.</span> <span class="n">IEEE</span><span class="p">,</span> <span class="mi">705</span><span class="o">-</span><span class="mf">714.</span>
</pre></div>
</div>
</li>
<li><p><strong>ASTGCN</strong>:</p>
<p>Attention-based spatio-temporal graph convolutional network, which combines the spatial-temporal attention mechanism and the spatial-temporal convolution to capture the dynamic spatial-temporal characteristics.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Shengnan Guo, Youfang Lin, Ning Feng, Chao Song, and Huaiyu Wan. 2019. Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting. In AAAI. AAAI Press, 922–929.
</pre></div>
</div>
</li>
<li><p><strong>MSTGCN</strong>:</p>
<p>A degraded version of ASTGCN, Multi-Component Spatial-Temporal Graph Convolution Networks (MSTGCN), which gets rid of the spatialtemporal attention.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Shengnan Guo, Youfang Lin, Ning Feng, Chao Song, and Huaiyu Wan. 2019. Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting. In AAAI. AAAI Press, 922–929.
</pre></div>
</div>
</li>
<li><p><strong>STDN</strong>:</p>
<p>Spatial-Temporal Dynamic Network (STDN), in which a flow gating mechanism is introduced to learn the dynamic similarity between locations, and a periodically shifted attention mechanism is designed to handle long-term periodic temporal shifting.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Huaxiu Yao, Xianfeng Tang, Hua Wei, Guanjie Zheng, and Zhenhui Li. 2019. Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction. In AAAI. AAAI Press, 5668–5675.
</pre></div>
</div>
</li>
<li><p><strong>AGCRN</strong>:</p>
<p>Adaptive Graph Convolutional Recurrent Network, which enhances the traditional graph convolution by adaptive modules and combines them into recurrent networks to capture fine-grained spatial and temporal correlations.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Lei</span> <span class="n">Bai</span><span class="p">,</span> <span class="n">Lina</span> <span class="n">Yao</span><span class="p">,</span> <span class="n">Can</span> <span class="n">Li</span><span class="p">,</span> <span class="n">Xianzhi</span> <span class="n">Wang</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Can</span> <span class="n">Wang</span><span class="o">.</span> <span class="mf">2020.</span> <span class="n">Adaptive</span> <span class="n">Graph</span> <span class="n">Convolutional</span> <span class="n">Recurrent</span> <span class="n">Network</span> <span class="k">for</span> <span class="n">Traffic</span> <span class="n">Forecasting</span><span class="o">.</span> <span class="n">In</span> <span class="n">NeurIPS</span><span class="o">.</span>
</pre></div>
</div>
</li>
<li><p><strong>DSAN</strong>:</p>
<p>Dynamic Switch-Attention Network (DSAN) with a novel Multi-Space Attention (MSA) mechanism, which dynamically extracts valuable information by applying selfattention over the noisy input and bridges each output directly.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Haoxing Lin, Rufan Bai, Weijia Jia, Xinyu Yang, and Yongjian You. 2020. Preserving Dynamic Attention for Long-Term Spatial-Temporal Prediction. In KDD. ACM, 36–46.
</pre></div>
</div>
</li>
<li><p><strong>STSGCN</strong>:</p>
<p>Spatial-Temporal Synchronous Graph Convolutional Networks (STSGCN), for spatial-temporal network data forecasting. The model is able to effectively capture the complex localized spatial-temporal correlations through an elaborately designed spatial-temporal synchronous modeling mechanism.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Chao Song, Youfang Lin, Shengnan Guo, and Huaiyu Wan. 2020. Spatial-Temporal Synchronous Graph Convolutional Networks: A New Framework for Spatial-Temporal Network Data Forecasting. In AAAI. AAAI Press, 914–921.
</pre></div>
</div>
</li>
<li><p><strong>Multi-STGCnet</strong>:</p>
<p>Multi-STGCnet contains three long short-term memory network (LSTM)-based modules as a temporal component and three spatial matrixes to extract spatial correlation of a target station as a spatial component.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Jiexia Ye, Juanjuan Zhao, Kejiang Ye, and Chengzhong Xu. 2020. Multi-STGCnet: A Graph Convolution Based Spatial-Temporal Framework for Subway Passenger Flow Forecasting. In IJCNN. IEEE, 1–8.
</pre></div>
</div>
</li>
<li><p><strong>DGCN</strong>:</p>
<p>DGCN is a novel dynamic graph convolution network for traffic forecasting, in which a latent network is introduced to extract spatial-temporal features for constructing the dynamic road network graph matrices adaptively.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Kan</span> <span class="n">Guo</span><span class="p">,</span> <span class="n">Yongli</span> <span class="n">Hu</span><span class="p">,</span> <span class="n">Zhen</span> <span class="n">Qian</span><span class="p">,</span> <span class="n">Yanfeng</span> <span class="n">Sun</span><span class="p">,</span> <span class="n">Junbin</span> <span class="n">Gao</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Baocai</span> <span class="n">Yin</span><span class="o">.</span> <span class="mf">2020.</span> <span class="n">Dynamic</span> <span class="n">Graph</span> <span class="n">Convolution</span> <span class="n">Network</span> <span class="k">for</span> <span class="n">Traffic</span> <span class="n">Forecasting</span> <span class="n">Based</span> <span class="n">on</span> <span class="n">Latent</span> <span class="n">Network</span> <span class="n">of</span> <span class="n">Laplace</span> <span class="n">Matrix</span> <span class="n">Estimation</span><span class="o">.</span> <span class="n">IEEE</span> <span class="n">Transactions</span> <span class="n">on</span> <span class="n">Intelligent</span> <span class="n">Transportation</span> <span class="n">Systems</span><span class="p">,</span> <span class="mi">23</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="mi">1009</span><span class="o">-</span><span class="mf">1018.</span>
</pre></div>
</div>
</li>
<li><p><strong>ResLSTM</strong>:</p>
<p>ResLSTM is a deep learning architecture combining the residual network (ResNet), graph convolutional network (GCN), and long short-term memory (LSTM) (called “ResLSTM”) to forecast short-term passenger flow in urban rail transit on a network scale.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Jinlei</span> <span class="n">Zhang</span><span class="p">,</span> <span class="n">Feng</span> <span class="n">Chen</span><span class="p">,</span> <span class="n">Zhiyong</span> <span class="n">Cui</span><span class="p">,</span> <span class="n">Yinan</span> <span class="n">Guo</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Yadi</span> <span class="n">Zhu</span><span class="o">.</span> <span class="mf">2020.</span> <span class="n">Deep</span><span class="o">-</span><span class="n">learning</span> <span class="n">Architecture</span> <span class="k">for</span> <span class="n">Short</span><span class="o">-</span><span class="n">term</span> <span class="n">Passenger</span> <span class="n">Flow</span> <span class="n">Forecasting</span> <span class="ow">in</span> <span class="n">Urban</span> <span class="n">Rail</span> <span class="n">Transit</span><span class="o">.</span> <span class="n">IEEE</span> <span class="n">Transactions</span> <span class="n">on</span> <span class="n">Intelligent</span> <span class="n">Transportation</span> <span class="n">Systems</span><span class="p">,</span> <span class="mi">22</span><span class="p">(</span><span class="mi">11</span><span class="p">),</span> <span class="mi">7004</span><span class="o">-</span><span class="mf">7014.</span>
</pre></div>
</div>
</li>
<li><p><strong>ToGCN</strong>:</p>
<p>Topological Graph Convolutional Network (ToGCN) followed with a Sequence-tosequence (Seq2Seq) framework to predict future traffic flow and density with temporal correlations.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Han</span> <span class="n">Qiu</span><span class="p">,</span> <span class="n">Qinkai</span> <span class="n">Zheng</span><span class="p">,</span> <span class="n">Mounira</span> <span class="n">Msahli</span><span class="p">,</span> <span class="n">Gerard</span> <span class="n">Memmi</span><span class="p">,</span> <span class="n">Meikang</span> <span class="n">Qiu</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Jialiang</span> <span class="n">Lu</span><span class="o">.</span> <span class="mf">2020.</span> <span class="n">Topological</span> <span class="n">Graph</span> <span class="n">Convolutional</span> <span class="n">Network</span><span class="o">-</span><span class="n">Based</span> <span class="n">Urban</span> <span class="n">Traffic</span> <span class="n">Flow</span> <span class="ow">and</span> <span class="n">Density</span> <span class="n">Prediction</span><span class="o">.</span> <span class="n">IEEE</span> <span class="n">Transactions</span> <span class="n">on</span> <span class="n">Intelligent</span> <span class="n">Transportation</span> <span class="n">Systems</span><span class="p">,</span> <span class="mi">22</span><span class="p">(</span><span class="mi">7</span><span class="p">),</span> <span class="mi">4560</span><span class="o">-</span><span class="mf">4569.</span>
</pre></div>
</div>
</li>
<li><p><strong>CONVGCN</strong>:</p>
<p>Conv-GCN combines a graph convolutional network (GCN) and a three-dimensional (3D) convolutional
neural network (3D CNN). The 3D CNN was used to innovatively integrate the inflow and outflow information as well as extract high-level correlations between three inflow/outflow patterns, and between stations located nearby and far away.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Jinlei</span> <span class="n">Zhang</span><span class="p">,</span> <span class="n">Feng</span> <span class="n">Chen</span><span class="p">,</span> <span class="n">Yinan</span> <span class="n">Guo</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Xiaohong</span> <span class="n">Li</span><span class="o">.</span> <span class="mf">2020.</span> <span class="n">Multi</span><span class="o">-</span><span class="n">graph</span> <span class="n">convolutional</span> <span class="n">network</span> <span class="k">for</span> <span class="n">short</span><span class="o">-</span><span class="n">term</span> <span class="n">passenger</span> <span class="n">flow</span> <span class="n">forecasting</span> <span class="ow">in</span> <span class="n">urban</span> <span class="n">rail</span> <span class="n">transit</span><span class="o">.</span> <span class="n">IET</span> <span class="n">Intelligent</span> <span class="n">Transport</span> <span class="n">Systems</span><span class="p">,</span> <span class="mi">14</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="mi">1210</span><span class="o">-</span><span class="mf">1217.</span>
</pre></div>
</div>
</li>
<li><p><strong>CRANN</strong>:</p>
<p>CRANN is an interpretable attention-based neural network in which several modules are combined in order to capture key spatio-temporal time series components.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Rodrigo</span> <span class="n">de</span> <span class="n">Medrano</span> <span class="ow">and</span> <span class="n">José</span> <span class="n">Luis</span> <span class="n">Aznarte</span><span class="o">.</span> <span class="mf">2020.</span> <span class="n">A</span> <span class="n">spatio</span><span class="o">-</span><span class="n">temporal</span> <span class="n">attention</span><span class="o">-</span><span class="n">based</span> <span class="n">spot</span><span class="o">-</span><span class="n">forecasting</span> <span class="n">framework</span> <span class="k">for</span> <span class="n">urban</span> <span class="n">traffic</span> <span class="n">prediction</span><span class="o">.</span> <span class="n">Applied</span> <span class="n">Soft</span> <span class="n">Computing</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mf">106615.</span>
</pre></div>
</div>
</li>
<li><p><strong>ST-Norm</strong>:</p>
<p>ST-Norm utilizes two kinds of normalization modules – temporal normalization (TN) and spatial normalization (SN) – which separately refine the high-frequency and local components</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Jinliang Deng, Xiusi Chen, Renhe Jiang, Xuan Song, and Ivor W. Tsang. 2021. ST-Norm: Spatial and Temporal Normalization for Multi-variate Time Series Forecasting. In KDD. ACM, 269–278.
</pre></div>
</div>
</li>
<li><p><strong>STGODE</strong>:</p>
<p>Spatial-Temporal Graph Ordinary Differential Equation Networks (STGODE) captures spatial-temporal dynamics through a tensor-based ordinary differential equation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Zheng</span> <span class="n">Fang</span><span class="p">,</span> <span class="n">Qingqing</span> <span class="n">Long</span><span class="p">,</span> <span class="n">Guojie</span> <span class="n">Song</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Kunqing</span> <span class="n">Xie</span><span class="o">.</span> <span class="mf">2021.</span> <span class="n">Spatial</span><span class="o">-</span><span class="n">Temporal</span> <span class="n">Graph</span> <span class="n">ODE</span> <span class="n">Networks</span> <span class="k">for</span> <span class="n">Traffic</span> <span class="n">Flow</span> <span class="n">Forecasting</span><span class="o">.</span> <span class="n">In</span> <span class="n">KDD</span><span class="o">.</span> <span class="n">ACM</span><span class="p">,</span> <span class="mi">364</span><span class="o">-</span><span class="mf">373.</span>
</pre></div>
</div>
</li>
<li><p><strong>ESG</strong>:</p>
<p>ESG uses a temporal convolution module and an evolving structure learner are particularly designed to learn the multi-scale representations of time series and a series of recurrent graph structures respectively.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Junchen</span> <span class="n">Ye</span><span class="p">,</span> <span class="n">Zihan</span> <span class="n">Liu</span><span class="p">,</span> <span class="n">Bowen</span> <span class="n">Du</span><span class="p">,</span> <span class="n">Leilei</span> <span class="n">Sun</span><span class="p">,</span> <span class="n">Weimiao</span> <span class="n">Li</span><span class="p">,</span> <span class="n">Yanjie</span> <span class="n">Fu</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Hui</span> <span class="n">Xiong</span><span class="o">.</span> <span class="mf">2022.</span> <span class="n">Learning</span> <span class="n">the</span> <span class="n">Evolutionary</span> <span class="ow">and</span> <span class="n">Multi</span><span class="o">-</span><span class="n">scale</span> <span class="n">Graph</span> <span class="n">Structure</span> <span class="k">for</span> <span class="n">Multivariate</span> <span class="n">Time</span> <span class="n">Series</span> <span class="n">Forecasting</span><span class="o">.</span> <span class="n">In</span> <span class="n">KDD</span><span class="o">.</span> <span class="n">ACM</span><span class="p">,</span> <span class="mi">2296</span><span class="o">-</span><span class="mf">2306.</span>
</pre></div>
</div>
</li>
<li><p><strong>FOGS</strong>:</p>
<p>First-Order Gradient Supervision (FOGS) uses a novel learning-based method to learn a spatial-temporal correlation graph and utilizes frst-order gradients, rather than specifc flows, to train prediction model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Xuan</span> <span class="n">Rao</span><span class="p">,</span> <span class="n">Hao</span> <span class="n">Wang</span><span class="p">,</span> <span class="n">Liang</span> <span class="n">Zhang</span><span class="p">,</span> <span class="n">Jing</span> <span class="n">Li</span><span class="p">,</span> <span class="n">Shuo</span> <span class="n">Shang</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Peng</span> <span class="n">Han</span><span class="o">.</span> <span class="mf">2022.</span> <span class="n">FOGS</span><span class="p">:</span> <span class="n">First</span><span class="o">-</span><span class="n">Order</span> <span class="n">Gradient</span> <span class="n">Supervision</span> <span class="k">with</span> <span class="n">Learning</span><span class="o">-</span><span class="n">based</span> <span class="n">Graph</span> <span class="k">for</span> <span class="n">Traffic</span> <span class="n">Flow</span> <span class="n">Forecasting</span><span class="o">.</span> <span class="n">In</span> <span class="n">IJCAI</span><span class="o">.</span> <span class="n">ijcai</span><span class="o">.</span><span class="n">org</span><span class="p">,</span> <span class="mi">3926</span><span class="o">-</span><span class="mf">3932.</span>
</pre></div>
</div>
</li>
<li><p><strong>ST-TSNet</strong>:</p>
<p>Spatial-temporal Transformer Network with Self-supervised Learning (ST-TSNet) uses a Pre-Conv Block and vision transformer to learn the spatial dependencies in both local and global contexts and explores spatial-temporal representations through a self-supervised strategy called stochastic augmentation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Zhangzhi</span> <span class="n">Peng</span> <span class="ow">and</span> <span class="n">Xiaohui</span> <span class="n">Huang</span><span class="o">.</span> <span class="mf">2022.</span> <span class="n">Spatial</span><span class="o">-</span><span class="n">temporal</span> <span class="n">Transformer</span> <span class="n">Network</span> <span class="k">with</span> <span class="n">Self</span><span class="o">-</span><span class="n">supervised</span> <span class="n">Learning</span> <span class="k">for</span> <span class="n">Traffic</span> <span class="n">Flow</span> <span class="n">Prediction</span><span class="o">.</span> <span class="n">In</span> <span class="n">STRL</span><span class="nd">@IJCAI</span><span class="o">.</span>
</pre></div>
</div>
</li>
<li><p><strong>SSTBAN</strong>:</p>
<p>Self-supervised Spatial-Temporal Bottleneck Attentive Network (SSTBAN) follows a multi-task framework by incorporating a self-supervised learner to produce robust latent representations for historical traffic data and uses a spatial-temporal bottleneck attention mechanism to capture the long-term temporal and spatial dynamics.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Shengnan</span> <span class="n">Guo</span><span class="p">,</span> <span class="n">Youfang</span> <span class="n">Lin</span><span class="p">,</span> <span class="n">Letian</span> <span class="n">Gong</span><span class="p">,</span> <span class="n">Chenyu</span> <span class="n">Wang</span><span class="p">,</span> <span class="n">Zeyu</span> <span class="n">Zhou</span><span class="p">,</span> <span class="n">Zekai</span> <span class="n">Shen</span><span class="p">,</span> <span class="n">Yiheng</span> <span class="n">Huang</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Huaiyu</span> <span class="n">Wan</span><span class="o">.</span> <span class="mf">2023.</span> <span class="n">Self</span><span class="o">-</span><span class="n">Supervised</span> <span class="n">Spatial</span><span class="o">-</span><span class="n">Temporal</span> <span class="n">Bottleneck</span> <span class="n">Attentive</span> <span class="n">Network</span> <span class="k">for</span> <span class="n">Efficient</span> <span class="n">Long</span><span class="o">-</span><span class="n">term</span> <span class="n">Traffic</span> <span class="n">Forecasting</span><span class="o">.</span> <span class="n">In</span> <span class="n">ICDE</span><span class="o">.</span> <span class="n">IEEE</span><span class="p">,</span> <span class="mi">1585</span><span class="o">-</span><span class="mf">1596.</span>
</pre></div>
</div>
</li>
</ul>
<ul>
<li><p><strong>ASTGNN</strong></p>
<p>This paper introduces an algorithm called Adaptive Graph Sparsification (AGS) to extremely sparsify the spatial adjacency matrices of Adaptive Spatial-Temporal Graph Neural Networks (ASTGNNs) without compromising test accuracy, thereby achieving localization of the models and exploring the role of spatial dependencies in the data.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Duan</span> <span class="n">W</span><span class="p">,</span> <span class="n">He</span> <span class="n">X</span><span class="p">,</span> <span class="n">Zhou</span> <span class="n">Z</span><span class="p">,</span> <span class="n">et</span> <span class="n">al</span><span class="o">.</span> <span class="n">Localised</span> <span class="n">adaptive</span> <span class="n">spatial</span><span class="o">-</span><span class="n">temporal</span> <span class="n">graph</span> <span class="n">neural</span> <span class="n">network</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">//</span><span class="n">Proceedings</span> <span class="n">of</span> <span class="n">the</span> <span class="mi">29</span><span class="n">th</span> <span class="n">acm</span> <span class="n">sigkdd</span> <span class="n">conference</span> <span class="n">on</span> <span class="n">knowledge</span> <span class="n">discovery</span> <span class="ow">and</span> <span class="n">data</span> <span class="n">mining</span><span class="o">.</span> <span class="mi">2023</span><span class="p">:</span> <span class="mi">448</span><span class="o">-</span><span class="mf">458.</span>
</pre></div>
</div>
</li>
<li><p><strong>DSTAGNN</strong></p>
<p>This paper introduces a novel Dynamic Spatial-Temporal Aware Graph Neural Network (DSTAGNN) for traffic flow forecasting, which models complex spatial-temporal interactions in road networks by mining dynamic attributes from historical traffic data without relying on predefined static adjacency matrices.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Lan</span> <span class="n">S</span><span class="p">,</span> <span class="n">Ma</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Huang</span> <span class="n">W</span><span class="p">,</span> <span class="n">et</span> <span class="n">al</span><span class="o">.</span> <span class="n">Dstagnn</span><span class="p">:</span> <span class="n">Dynamic</span> <span class="n">spatial</span><span class="o">-</span><span class="n">temporal</span> <span class="n">aware</span> <span class="n">graph</span> <span class="n">neural</span> <span class="n">network</span> <span class="k">for</span> <span class="n">traffic</span> <span class="n">flow</span> <span class="n">forecasting</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">//</span><span class="n">International</span> <span class="n">conference</span> <span class="n">on</span> <span class="n">machine</span> <span class="n">learning</span><span class="o">.</span> <span class="n">PMLR</span><span class="p">,</span> <span class="mi">2022</span><span class="p">:</span> <span class="mi">11906</span><span class="o">-</span><span class="mf">11917.</span>
</pre></div>
</div>
</li>
<li><p><strong>MultiSPANS</strong></p>
<p>The paper presents a novel deep learning framework designed to improve traffic flow prediction by capturing complex multi-range dependencies using local spatiotemporal features and road network hierarchical knowledge. The authors propose a multi-filter convolution module to generate informative ST-token embeddings, which are then used by Transformers to capture long-range temporal and spatial dependencies.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Zou</span> <span class="n">D</span><span class="p">,</span> <span class="n">Wang</span> <span class="n">S</span><span class="p">,</span> <span class="n">Li</span> <span class="n">X</span><span class="p">,</span> <span class="n">et</span> <span class="n">al</span><span class="o">.</span> <span class="n">Multispans</span><span class="p">:</span> <span class="n">A</span> <span class="n">multi</span><span class="o">-</span><span class="nb">range</span> <span class="n">spatial</span><span class="o">-</span><span class="n">temporal</span> <span class="n">transformer</span> <span class="n">network</span> <span class="k">for</span> <span class="n">traffic</span> <span class="n">forecast</span> <span class="n">via</span> <span class="n">structural</span> <span class="n">entropy</span> <span class="n">optimization</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">//</span><span class="n">Proceedings</span> <span class="n">of</span> <span class="n">the</span> <span class="mi">17</span><span class="n">th</span> <span class="n">ACM</span> <span class="n">International</span> <span class="n">Conference</span> <span class="n">on</span> <span class="n">Web</span> <span class="n">Search</span> <span class="ow">and</span> <span class="n">Data</span> <span class="n">Mining</span><span class="o">.</span> <span class="mi">2024</span><span class="p">:</span> <span class="mi">1032</span><span class="o">-</span><span class="mf">1041.</span>
</pre></div>
</div>
</li>
<li><p><strong>Multi-STGCNet</strong></p>
<p>The paper introduces Multi-STGCnet, a spatio-temporal deep learning framework utilizing LSTM and GCN modules to forecast short-term subway passenger flow, outperforming multiple baselines on a Shenzhen metro dataset.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Ye</span> <span class="n">J</span><span class="p">,</span> <span class="n">Zhao</span> <span class="n">J</span><span class="p">,</span> <span class="n">Ye</span> <span class="n">K</span><span class="p">,</span> <span class="n">et</span> <span class="n">al</span><span class="o">.</span> <span class="n">Multi</span><span class="o">-</span><span class="n">stgcnet</span><span class="p">:</span> <span class="n">A</span> <span class="n">graph</span> <span class="n">convolution</span> <span class="n">based</span> <span class="n">spatial</span><span class="o">-</span><span class="n">temporal</span> <span class="n">framework</span> <span class="k">for</span> <span class="n">subway</span> <span class="n">passenger</span> <span class="n">flow</span> <span class="n">forecasting</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">//</span><span class="mi">2020</span> <span class="n">International</span> <span class="n">joint</span> <span class="n">conference</span> <span class="n">on</span> <span class="n">neural</span> <span class="n">networks</span> <span class="p">(</span><span class="n">IJCNN</span><span class="p">)</span><span class="o">.</span> <span class="n">IEEE</span><span class="p">,</span> <span class="mi">2020</span><span class="p">:</span> <span class="mi">1</span><span class="o">-</span><span class="mf">8.</span>
</pre></div>
</div>
</li>
<li><p><strong>PDFormer</strong></p>
<p>The paper introduces a novel model designed to address the challenges of accurately predicting traffic flow by capturing complex spatial-temporal dependencies in traffic data. The PDFormer model incorporates a spatial self-attention module to dynamically model spatial dependencies, graph masking matrices to highlight short- and long-range spatial dependencies, and a delay-aware feature transformation module to explicitly account for the time delay in spatial information propagation. The paper demonstrates the model’s effectiveness through extensive experiments on six real-world public traffic datasets, showing state-of-the-art performance and competitive computational efficiency.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Jiang</span> <span class="n">J</span><span class="p">,</span> <span class="n">Han</span> <span class="n">C</span><span class="p">,</span> <span class="n">Zhao</span> <span class="n">W</span> <span class="n">X</span><span class="p">,</span> <span class="n">et</span> <span class="n">al</span><span class="o">.</span> <span class="n">Pdformer</span><span class="p">:</span> <span class="n">Propagation</span> <span class="n">delay</span><span class="o">-</span><span class="n">aware</span> <span class="n">dynamic</span> <span class="n">long</span><span class="o">-</span><span class="nb">range</span> <span class="n">transformer</span> <span class="k">for</span> <span class="n">traffic</span> <span class="n">flow</span> <span class="n">prediction</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">//</span><span class="n">Proceedings</span> <span class="n">of</span> <span class="n">the</span> <span class="n">AAAI</span> <span class="n">conference</span> <span class="n">on</span> <span class="n">artificial</span> <span class="n">intelligence</span><span class="o">.</span> <span class="mi">2023</span><span class="p">,</span> <span class="mi">37</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span> <span class="mi">4365</span><span class="o">-</span><span class="mf">4373.</span>
</pre></div>
</div>
</li>
<li><p><strong>RGSL</strong></p>
<p>The paper introduces a novel model named RGSL for multivariate time-series forecasting. The RGSL model incorporates both explicit prior structure and implicit structure to learn the forecasting deep networks along with the graph structure. It consists of two main modules: the Regularized Graph Generation (RGG) module, which learns the sparse graph structure using the Gumbel Softmax trick, and the Laplacian Matrix Mixed-up Module (LM3), which fuses the explicit graph and implicit graph together. The paper demonstrates that RGSL outperforms existing graph forecasting algorithms with a significant margin while also learning meaningful graph structures.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Yu</span> <span class="n">H</span><span class="p">,</span> <span class="n">Li</span> <span class="n">T</span><span class="p">,</span> <span class="n">Yu</span> <span class="n">W</span><span class="p">,</span> <span class="n">et</span> <span class="n">al</span><span class="o">.</span> <span class="n">Regularized</span> <span class="n">graph</span> <span class="n">structure</span> <span class="n">learning</span> <span class="k">with</span> <span class="n">semantic</span> <span class="n">knowledge</span> <span class="k">for</span> <span class="n">multi</span><span class="o">-</span><span class="n">variates</span> <span class="n">time</span><span class="o">-</span><span class="n">series</span> <span class="n">forecasting</span><span class="p">[</span><span class="n">J</span><span class="p">]</span><span class="o">.</span> <span class="n">arXiv</span> <span class="n">preprint</span> <span class="n">arXiv</span><span class="p">:</span><span class="mf">2210.06126</span><span class="p">,</span> <span class="mf">2022.</span>
</pre></div>
</div>
</li>
<li><p><strong>STG-NCDE</strong></p>
<p>The paper introduces a novel method called STG-NCDE (Spatio-Temporal Graph Neural Controlled Differential Equations) for spatio-temporal traffic forecasting. The authors propose a framework that combines two neural controlled differential equations (NCDEs): one for temporal processing and another for spatial processing. The STG-NCDE model is designed to capture complex spatial-temporal dependencies in traffic data by integrating graph convolutional network (GCN) technology with NCDEs. The paper reports that STG-NCDE outperforms 20 baseline methods across six benchmark datasets, demonstrating its effectiveness in real-world traffic forecasting tasks.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Choi</span> <span class="n">J</span><span class="p">,</span> <span class="n">Choi</span> <span class="n">H</span><span class="p">,</span> <span class="n">Hwang</span> <span class="n">J</span><span class="p">,</span> <span class="n">et</span> <span class="n">al</span><span class="o">.</span> <span class="n">Graph</span> <span class="n">neural</span> <span class="n">controlled</span> <span class="n">differential</span> <span class="n">equations</span> <span class="k">for</span> <span class="n">traffic</span> <span class="n">forecasting</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">//</span><span class="n">Proceedings</span> <span class="n">of</span> <span class="n">the</span> <span class="n">AAAI</span> <span class="n">conference</span> <span class="n">on</span> <span class="n">artificial</span> <span class="n">intelligence</span><span class="o">.</span> <span class="mi">2022</span><span class="p">,</span> <span class="mi">36</span><span class="p">(</span><span class="mi">6</span><span class="p">):</span> <span class="mi">6367</span><span class="o">-</span><span class="mf">6374.</span>
</pre></div>
</div>
</li>
<li><p><strong>STPGCN</strong></p>
<p>The paper addresses the importance of capturing correlations between road network nodes for improving traffic flow forecasting accuracy. It highlights spatial, temporal, and joint spatial-temporal correlations between nodes, which are influenced by their spatial and temporal position factors. The paper proposes a novel Spatial-Temporal Position-aware Graph Convolution Network (STPGCN) to address three main issues with existing models: ineffective modeling of joint spatial-temporal correlations, ignoring spatial and temporal position factors, and failure to capture distinct spatial-temporal patterns for each node. The STPGCN incorporates a trainable embedding module for node positions, a relation inference module to adaptively infer correlation weights, and a gated activation unit in graph convolution to capture node-specific pattern features. The model demonstrates superior prediction performance and computational efficiency through extensive experiments on six real-world datasets.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Zhao</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Lin</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Wen</span> <span class="n">H</span><span class="p">,</span> <span class="n">et</span> <span class="n">al</span><span class="o">.</span> <span class="n">Spatial</span><span class="o">-</span><span class="n">temporal</span> <span class="n">position</span><span class="o">-</span><span class="n">aware</span> <span class="n">graph</span> <span class="n">convolution</span> <span class="n">networks</span> <span class="k">for</span> <span class="n">traffic</span> <span class="n">flow</span> <span class="n">forecasting</span><span class="p">[</span><span class="n">J</span><span class="p">]</span><span class="o">.</span> <span class="n">IEEE</span> <span class="n">Transactions</span> <span class="n">on</span> <span class="n">Intelligent</span> <span class="n">Transportation</span> <span class="n">Systems</span><span class="p">,</span> <span class="mi">2022</span><span class="p">,</span> <span class="mi">24</span><span class="p">(</span><span class="mi">8</span><span class="p">):</span> <span class="mi">8650</span><span class="o">-</span><span class="mf">8666.</span>
</pre></div>
</div>
</li>
<li><p><strong>STSSL</strong></p>
<p>The paper introduces a novel framework called ST-SSL for enhancing traffic pattern representations to reflect both spatial and temporal heterogeneity, using self-supervised learning paradigms. The ST-SSL framework incorporates temporal and spatial convolutions for encoding information across space and time, and includes an adaptive augmentation over traffic flow graph data at attribute and structure levels. It also constructs two self-supervised learning tasks to supplement the main traffic prediction task with spatial and temporal heterogeneity-aware augmentation. The paper reports that extensive experiments on four real-world public datasets demonstrate the superiority of the ST-SSL model in terms of prediction performance and computational efficiency.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Ji</span> <span class="n">J</span><span class="p">,</span> <span class="n">Wang</span> <span class="n">J</span><span class="p">,</span> <span class="n">Huang</span> <span class="n">C</span><span class="p">,</span> <span class="n">et</span> <span class="n">al</span><span class="o">.</span> <span class="n">Spatio</span><span class="o">-</span><span class="n">temporal</span> <span class="bp">self</span><span class="o">-</span><span class="n">supervised</span> <span class="n">learning</span> <span class="k">for</span> <span class="n">traffic</span> <span class="n">flow</span> <span class="n">prediction</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">//</span><span class="n">Proceedings</span> <span class="n">of</span> <span class="n">the</span> <span class="n">AAAI</span> <span class="n">conference</span> <span class="n">on</span> <span class="n">artificial</span> <span class="n">intelligence</span><span class="o">.</span> <span class="mi">2023</span><span class="p">,</span> <span class="mi">37</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span> <span class="mi">4356</span><span class="o">-</span><span class="mf">4364.</span>
</pre></div>
</div>
</li>
<li><p><strong>STWave</strong></p>
<p>The paper addresses the challenge of traffic forecasting, which is essential for public safety and resource optimization but is complicated by the temporal changes and dynamic spatial correlations in traffic data. The authors propose a novel framework called STWave that disentangles complex traffic data into stable trends and fluctuating events, and then models these separately using a dual-channel spatio-temporal network. The framework also incorporates a query sampling strategy and graph wavelet-based graph positional encoding to efficiently and effectively model dynamic spatial correlations. Extensive experiments on six traffic datasets demonstrate the superiority of the approach, with higher forecasting accuracy and lower computational cost compared to previous methods.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Fang</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Qin</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Luo</span> <span class="n">H</span><span class="p">,</span> <span class="n">et</span> <span class="n">al</span><span class="o">.</span> <span class="n">When</span> <span class="n">spatio</span><span class="o">-</span><span class="n">temporal</span> <span class="n">meet</span> <span class="n">wavelets</span><span class="p">:</span> <span class="n">Disentangled</span> <span class="n">traffic</span> <span class="n">forecasting</span> <span class="n">via</span> <span class="n">efficient</span> <span class="n">spectral</span> <span class="n">graph</span> <span class="n">attention</span> <span class="n">networks</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">//</span><span class="mi">2023</span> <span class="n">IEEE</span> <span class="mi">39</span><span class="n">th</span> <span class="n">International</span> <span class="n">Conference</span> <span class="n">on</span> <span class="n">Data</span> <span class="n">Engineering</span> <span class="p">(</span><span class="n">ICDE</span><span class="p">)</span><span class="o">.</span> <span class="n">IEEE</span><span class="p">,</span> <span class="mi">2023</span><span class="p">:</span> <span class="mi">517</span><span class="o">-</span><span class="mf">529.</span>
</pre></div>
</div>
</li>
<li><p><strong>SimST</strong></p>
<p>The paper introduces a novel framework for traffic forecasting that does not rely on Graph Neural Networks (GNNs). Instead, SimST uses two efficient spatial context injectors to provide proximity and position information, replacing the traditional message passing scheme of GNNs. The framework is compatible with various temporal encoding backbones and includes a tailored training strategy. Extensive experiments on five traffic benchmarks demonstrate that SimST performs surprisingly well, achieving comparable or better performance than more sophisticated state-of-the-art STGNNs while using significantly fewer parameters and obtaining substantial throughput improvements. The paper suggests that message passing in GNNs is not necessary for effective spatial modeling in traffic forecasting, challenging the prevailing practice in the field and opening up new research possibilities.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Liu</span> <span class="n">X</span><span class="p">,</span> <span class="n">Liang</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Huang</span> <span class="n">C</span><span class="p">,</span> <span class="n">et</span> <span class="n">al</span><span class="o">.</span> <span class="n">SimST</span><span class="p">:</span> <span class="n">A</span> <span class="n">GNN</span><span class="o">-</span><span class="n">Free</span> <span class="n">Spatio</span><span class="o">-</span><span class="n">Temporal</span> <span class="n">Learning</span> <span class="n">Framework</span> <span class="k">for</span> <span class="n">Traffic</span> <span class="n">Forecasting</span><span class="p">[</span><span class="n">J</span><span class="p">]</span><span class="o">.</span>
</pre></div>
</div>
</li>
<li><p><strong>TimeMixer</strong></p>
<p>This paper introduces TimeMixer, a novel multiscale mixing architecture for time series forecasting that achieves state-of-the-art performance by leveraging disentangled multiscale series in both past extraction and future prediction phases.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Wang</span> <span class="n">S</span><span class="p">,</span> <span class="n">Wu</span> <span class="n">H</span><span class="p">,</span> <span class="n">Shi</span> <span class="n">X</span><span class="p">,</span> <span class="n">et</span> <span class="n">al</span><span class="o">.</span> <span class="n">Timemixer</span><span class="p">:</span> <span class="n">Decomposable</span> <span class="n">multiscale</span> <span class="n">mixing</span> <span class="k">for</span> <span class="n">time</span> <span class="n">series</span> <span class="n">forecasting</span><span class="p">[</span><span class="n">J</span><span class="p">]</span><span class="o">.</span> <span class="n">arXiv</span> <span class="n">preprint</span> <span class="n">arXiv</span><span class="p">:</span><span class="mf">2405.14616</span><span class="p">,</span> <span class="mf">2024.</span>
</pre></div>
</div>
</li>
<li><p><strong>FreTS</strong></p>
<p>This paper introduces a new model named FreTS (Frequency-domain MLPs for Time Series forecasting), which applies multi-layer perceptrons (MLPs) in the frequency domain to capture complex spatial-temporal dependencies in time series data more effectively than traditional time-domain or separate encoding methods. FreTS unifies spatial and temporal information within a single transformer-style model, enabling every node at every timestamp to interact with every other node in every other timestamp in just one step through the spatial-temporal correlation matrix. This design allows FreTS to capture global periodic patterns and key features while filtering out noise.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Yi</span> <span class="n">K</span><span class="p">,</span> <span class="n">Zhang</span> <span class="n">Q</span><span class="p">,</span> <span class="n">Fan</span> <span class="n">W</span><span class="p">,</span> <span class="n">et</span> <span class="n">al</span><span class="o">.</span> <span class="n">Frequency</span><span class="o">-</span><span class="n">domain</span> <span class="n">MLPs</span> <span class="n">are</span> <span class="n">more</span> <span class="n">effective</span> <span class="n">learners</span> <span class="ow">in</span> <span class="n">time</span> <span class="n">series</span> <span class="n">forecasting</span><span class="p">[</span><span class="n">J</span><span class="p">]</span><span class="o">.</span> <span class="n">Advances</span> <span class="ow">in</span> <span class="n">Neural</span> <span class="n">Information</span> <span class="n">Processing</span> <span class="n">Systems</span><span class="p">,</span> <span class="mi">2024</span><span class="p">,</span> <span class="mf">36.</span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="traffic-speed-prediction">
<h2>Traffic Speed Prediction<a class="headerlink" href="#traffic-speed-prediction" title="Permalink to this heading"></a></h2>
<ul>
<li><p><strong>DCRNN</strong>:</p>
<p>Diffusion Convolution Recurrent Neural Network, which captures the spatial dependency using graph convolution formulated by diffusion process and the temporal dependency using the encoder-decoder framework.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Yaguang</span> <span class="n">Li</span><span class="p">,</span> <span class="n">Rose</span> <span class="n">Yu</span><span class="p">,</span> <span class="n">Cyrus</span> <span class="n">Shahabi</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Yan</span> <span class="n">Liu</span><span class="o">.</span> <span class="mf">2018.</span> <span class="n">Diffusion</span> <span class="n">Convolutional</span> <span class="n">Recurrent</span> <span class="n">Neural</span> <span class="n">Network</span><span class="p">:</span> <span class="n">Data</span><span class="o">-</span><span class="n">Driven</span> <span class="n">Traffic</span> <span class="n">Forecasting</span><span class="o">.</span> <span class="n">In</span> <span class="n">ICLR</span><span class="o">.</span> <span class="n">OpenReview</span><span class="o">.</span><span class="n">net</span><span class="o">.</span>
</pre></div>
</div>
</li>
<li><p><strong>STGCN</strong>:</p>
<p>Spatial-Temporal Graph Convolutional Network, which combines graph convolutions and gated temporal convolution to capture spatial and temporal correlations.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Bing Yu, Haoteng Yin, and Zhanxing Zhu. 2018. Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting. In IJCAI. ijcai.org, 3634–3640.
</pre></div>
</div>
</li>
<li><p><strong>GWNET</strong>:</p>
<p>Graph WaveNet, a spatial-temporal graph convolutional network integrating diffusion convolution with 1D dilated casual convolution to capture spatiotemporal dependencies.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Zonghan Wu, Shirui Pan, Guodong Long, Jing Jiang, and Chengqi Zhang. 2019. Graph WaveNet for Deep Spatial-Temporal Graph Modeling. In IJCAI. ijcai.org, 1907–1913.
</pre></div>
</div>
</li>
<li><p><strong>T-GCN</strong>:</p>
<p>Temporal Graph Convolution Model, which is in combination with the graph convolutional network and gated recurrent unit to capture spatial and temporal correlations.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Ling</span> <span class="n">Zhao</span><span class="p">,</span> <span class="n">Yujiao</span> <span class="n">Song</span><span class="p">,</span> <span class="n">Chao</span> <span class="n">Zhang</span><span class="p">,</span> <span class="n">Yu</span> <span class="n">Liu</span><span class="p">,</span> <span class="n">Pu</span> <span class="n">Wang</span><span class="p">,</span> <span class="n">Tao</span> <span class="n">Lin</span><span class="p">,</span> <span class="n">Min</span> <span class="n">Deng</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Haifeng</span> <span class="n">Li</span><span class="o">.</span> <span class="mf">2019.</span> <span class="n">T</span><span class="o">-</span><span class="n">GCN</span><span class="p">:</span> <span class="n">A</span> <span class="n">Temporal</span> <span class="n">Graph</span> <span class="n">Convolutional</span> <span class="n">Network</span> <span class="k">for</span> <span class="n">Traffic</span> <span class="n">Prediction</span><span class="o">.</span> <span class="n">IEEE</span> <span class="n">Transactions</span> <span class="n">on</span> <span class="n">Intelligent</span> <span class="n">Transportation</span> <span class="n">Systems</span><span class="p">,</span> <span class="mi">21</span><span class="p">(</span><span class="mi">9</span><span class="p">),</span> <span class="mi">3848</span><span class="o">-</span><span class="mf">3858.</span>
</pre></div>
</div>
</li>
<li><p><strong>MTGNN</strong>:</p>
<p>A graph neural network framework designed specifically for multivariate time series data, which combines graph convolutional network with mix-hop propagation layer and dilated inception layer to capture the spatial and temporal dependencies.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Zonghan Wu, Shirui Pan, Guodong Long, Jing Jiang, Xiaojun Chang, and Chengqi Zhang. 2020. Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks. In KDD. ACM, 753–763.
</pre></div>
</div>
</li>
<li><p><strong>GMAN</strong>:</p>
<p>GMAN adapts an encoder-decoder architecture, where both the encoder and the decoder consist of multiple spatio-temporal attention blocks to model the impact of the spatio-temporal factors on traffic conditions.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Chuanpan Zheng, Xiaoliang Fan, Cheng Wang, and Jianzhong Qi. 2020. GMAN: A Graph Multi-Attention Network for Traffic Prediction. In AAAI. AAAI Press,1234–1241.
</pre></div>
</div>
</li>
<li><p><strong>STAGGCN</strong>:</p>
<p>STAGGCN exploits spatio-temporal correlation of urban traffic flow and construct a dynamic weighted graph by seeking both spatial neighbors and semantic neighbors of road nodes.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Bin Lu, Xiaoying Gan, Haiming Jin, Luoyi Fu, and Haisong Zhang. 2020. Spatio-temporal Adaptive Gated Graph Convolution Network for Urban Traffic Flow Forecasting. In CIKM. ACM, 1025–1034.
</pre></div>
</div>
</li>
<li><p><strong>ST-MGAT</strong>:</p>
<p>Spatial-Temporal Multi-head Graph ATtention network (ST-MGAT), which build convolutions on the graph directly and consider the features of neighborhood nodes and the weights of the edges to generate new node representation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Kelang Tian, Jingjie Guo, Kejiang Ye, and Cheng-Zhong Xu. 2020. ST-MGAT: Spatial-Temporal Multi-Head Graph Attention Networks for Traffic Forecasting. In ICTAI. IEEE, 714–721.
</pre></div>
</div>
</li>
<li><p><strong>DKFN</strong>:</p>
<p>Deep Kalman Filtering Network (DKFN) to forecast the network-wide traffic state by modeling the self and neighbor dependencies as two streams, and their predictions are fused under the statistical theory and optimized through the Kalman filtering network.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Fanglan Chen, Zhiqian Chen, Subhodip Biswas, Shuo Lei, Naren Ramakrishnan, and Chang-Tien Lu. 2020. Graph Convolutional Networks with Kalman Filtering for Traffic Prediction. In SIGSPATIAL. ACM, 135–138.
</pre></div>
</div>
</li>
<li><p><strong>TGC-LSTM</strong>:</p>
<p>Traffic Graph Convolutional Long Short-Term Memory Neural Network (TGC-LSTM), to learn the interactions between roadways in the traffic network and forecast the network-wide traffic state.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Zhiyong</span> <span class="n">Cui</span><span class="p">,</span> <span class="n">Kristian</span> <span class="n">Henrickson</span><span class="p">,</span> <span class="n">Ruimin</span> <span class="n">Ke</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Yinhai</span> <span class="n">Wang</span><span class="o">.</span> <span class="mf">2020.</span> <span class="n">Traffic</span> <span class="n">Graph</span> <span class="n">Convolutional</span> <span class="n">Recurrent</span> <span class="n">Neural</span> <span class="n">Network</span><span class="p">:</span> <span class="n">A</span> <span class="n">Deep</span> <span class="n">Learning</span> <span class="n">Frame</span> <span class="n">work</span> <span class="k">for</span> <span class="n">Network</span><span class="o">-</span><span class="n">Scale</span> <span class="n">Traffic</span> <span class="n">Learning</span> <span class="ow">and</span> <span class="n">Forecasting</span><span class="o">.</span> <span class="n">IEEE</span> <span class="n">Transactions</span> <span class="n">on</span> <span class="n">Intelligent</span> <span class="n">Transportation</span> <span class="n">Systems</span><span class="p">,</span> <span class="mi">21</span><span class="p">(</span><span class="mi">11</span><span class="p">),</span> <span class="mi">4883</span><span class="o">-</span><span class="mf">4894.</span>
</pre></div>
</div>
</li>
</ul>
<ul>
<li><p><strong>STTN</strong>:</p>
<p>The model uses the Transformer structure of time and space for traffic prediction.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Mingxing</span> <span class="n">Xu</span><span class="p">,</span> <span class="n">Wenrui</span> <span class="n">Dai</span><span class="p">,</span> <span class="n">Chunmiao</span> <span class="n">Liu</span><span class="p">,</span> <span class="n">Xing</span> <span class="n">Gao</span><span class="p">,</span> <span class="n">Weiyao</span> <span class="n">Lin</span><span class="p">,</span> <span class="n">Guo</span><span class="o">-</span><span class="n">Jun</span><span class="p">,</span> <span class="n">Qi</span> <span class="ow">and</span> <span class="n">Hongkai</span> <span class="n">Xiong</span><span class="o">.</span> <span class="mf">2020.</span> <span class="n">Spatial</span><span class="o">-</span><span class="n">Temporal</span> <span class="n">Transformer</span> <span class="n">Networks</span> <span class="k">for</span> <span class="n">Traffic</span> <span class="n">Flow</span> <span class="n">Forecasting</span><span class="o">.</span> <span class="n">arXiv</span> <span class="n">preprint</span> <span class="n">arXiv</span><span class="p">:</span><span class="mf">2001.02908</span><span class="o">.</span>
</pre></div>
</div>
</li>
</ul>
<ul>
<li><p><strong>GTS</strong>:</p>
<p>GTS is a learning the structure simultaneously with the GNN if the graph is unknown, and is a probabilistic graph model through optimizing the mean performance over the graph distribution.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Chao</span> <span class="n">Shang</span><span class="p">,</span> <span class="n">Jie</span> <span class="n">Chen</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Jinbo</span> <span class="n">Bi</span><span class="o">.</span> <span class="mf">2021.</span> <span class="n">Discrete</span> <span class="n">Graph</span> <span class="n">Structure</span> <span class="n">Learning</span> <span class="k">for</span> <span class="n">Forecasting</span> <span class="n">Multiple</span> <span class="n">Time</span> <span class="n">Series</span><span class="o">.</span> <span class="n">In</span> <span class="n">ICLR</span><span class="o">.</span> <span class="n">OpenReview</span><span class="o">.</span><span class="n">net</span><span class="o">.</span>
</pre></div>
</div>
</li>
</ul>
<ul>
<li><p><strong>DMSTGCN</strong></p>
<p>Dynamic and Multi-faceted Spatio-Temporal Graph Convolution Network (DMSTGCN) propagates hidden states of nodes according to dynamic spatial relationships through a dynamic graph constructor and the dynamic graph convolution method. It also utilizes a multi-faceted fusion module to incorporate the auxiliary hidden states with primary hidden states spatially and temporally.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Liangzhe</span> <span class="n">Han</span><span class="p">,</span> <span class="n">Bowen</span> <span class="n">Du</span><span class="p">,</span> <span class="n">Leilei</span> <span class="n">Sun</span><span class="p">,</span> <span class="n">Yanjie</span> <span class="n">Fu</span><span class="p">,</span> <span class="n">Yisheng</span> <span class="n">Lv</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Hui</span> <span class="n">Xiong</span><span class="o">.</span> <span class="mf">2021.</span> <span class="n">Dynamic</span> <span class="ow">and</span> <span class="n">Multi</span><span class="o">-</span><span class="n">faceted</span> <span class="n">Spatio</span><span class="o">-</span><span class="n">temporal</span> <span class="n">Deep</span> <span class="n">Learning</span> <span class="k">for</span> <span class="n">Traffic</span> <span class="n">Speed</span> <span class="n">Forecasting</span><span class="o">.</span> <span class="n">In</span> <span class="n">KDD</span><span class="o">.</span> <span class="n">ACM</span><span class="p">,</span> <span class="mi">547</span><span class="o">-</span><span class="mf">555.</span>
</pre></div>
</div>
</li>
</ul>
<ul>
<li><p><strong>HGCN</strong>:</p>
<p>Hierarchical Graph Convolution Networks (HGCN) for traffic forecasting by operating on both the micro and macro traffic graphs.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Kan</span> <span class="n">Guo</span><span class="p">,</span> <span class="n">Yongli</span> <span class="n">Hu</span><span class="p">,</span> <span class="n">Yanfeng</span> <span class="n">Sun</span><span class="p">,</span> <span class="n">Sean</span> <span class="n">Qian</span><span class="p">,</span> <span class="n">Junbin</span> <span class="n">Gao</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Baocai</span> <span class="n">Yin</span><span class="o">.</span> <span class="mf">2021.</span> <span class="n">Hierarchical</span> <span class="n">Graph</span> <span class="n">Convolution</span> <span class="n">Networks</span> <span class="k">for</span> <span class="n">Traffic</span> <span class="n">Forecasting</span><span class="o">.</span> <span class="n">In</span> <span class="n">AAAI</span><span class="o">.</span> <span class="n">AAAI</span> <span class="n">Press</span><span class="p">,</span> <span class="mi">151</span><span class="o">-</span><span class="mf">159.</span>
</pre></div>
</div>
</li>
<li><p><strong>ATDM</strong>:</p>
<p>ATDM is a model with the use of prior spatial knowledge. It is a convolution-based neural network for regression with their respective spatial agnostic versions.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Rodrigo</span> <span class="n">de</span> <span class="n">Medrano</span> <span class="ow">and</span> <span class="n">José</span> <span class="n">Luis</span> <span class="n">Aznarte</span><span class="o">.</span> <span class="mf">2021.</span> <span class="n">On</span> <span class="n">the</span> <span class="n">Inclusion</span> <span class="n">of</span> <span class="n">Spatial</span> <span class="n">Information</span> <span class="k">for</span> <span class="n">Spatio</span><span class="o">-</span><span class="n">Temporal</span> <span class="n">Neural</span> <span class="n">Networks</span><span class="o">.</span> <span class="n">Neural</span> <span class="n">Computing</span> <span class="ow">and</span> <span class="n">Applications</span><span class="p">,</span> <span class="mi">33</span><span class="p">(</span><span class="mi">21</span><span class="p">),</span> <span class="mi">14723</span><span class="o">-</span><span class="mf">14740.</span>
</pre></div>
</div>
</li>
</ul>
<ul>
<li><p><strong>STID</strong></p>
<p>STID is a simple yet effective baseline for MTS forecasting by attaching spatial and temporal identity information.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Zezhi Shao, Zhao Zhang, Fei Wang, Wei Wei, and Yongjun Xu. 2022. Spatial-Temporal Identity: A Simple yet Effective Baseline for Multivariate Time Series Forecasting. In CIKM. ACM, 4454–4458.
</pre></div>
</div>
</li>
<li><p><strong>D2STGNN</strong></p>
<p>Decoupled Dynamic Spatial-Temporal Graph Neural Network (D2STGNN) decouples the hidden time series generated by the diffusion process and the hidden time series that is independent of other sensors. It also takes into account the dynamic nature of spatial dependency through a dynamic graph learning module.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Zezhi Shao, Zhao Zhang, Wei Wei, Fei Wang, Yongjun Xu, Xin Cao, and Christian S. Jensen. 2022. Decoupled Dynamic Spatial-Temporal Graph Neural Network for Traffic Forecasting. In VLDB. ACM, 2733–2746.
</pre></div>
</div>
</li>
<li><p><strong>HIEST</strong></p>
<p>This paper discusses a novel approach to traffic forecasting in the context of smart city construction. The authors propose a method called HIEST, which captures sensor dependencies from regional and global perspectives to enhance spatio-temporal prediction. The paper introduces the construction of regional and global graphs to reflect macro dependencies and common spatio-temporal patterns among sensors, respectively. It also presents a Cross-Hierarchy Graph Convolutional Network (CHGCN) for information propagation across different hierarchies.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Ma</span> <span class="n">Q</span><span class="p">,</span> <span class="n">Zhang</span> <span class="n">Z</span><span class="p">,</span> <span class="n">Zhao</span> <span class="n">X</span><span class="p">,</span> <span class="n">et</span> <span class="n">al</span><span class="o">.</span> <span class="n">Rethinking</span> <span class="n">sensors</span> <span class="n">modeling</span><span class="p">:</span> <span class="n">Hierarchical</span> <span class="n">information</span> <span class="n">enhanced</span> <span class="n">traffic</span> <span class="n">forecasting</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">//</span><span class="n">Proceedings</span> <span class="n">of</span> <span class="n">the</span> <span class="mi">32</span><span class="n">nd</span> <span class="n">ACM</span> <span class="n">International</span> <span class="n">Conference</span> <span class="n">on</span> <span class="n">Information</span> <span class="ow">and</span> <span class="n">Knowledge</span> <span class="n">Management</span><span class="o">.</span> <span class="mi">2023</span><span class="p">:</span> <span class="mi">1756</span><span class="o">-</span><span class="mf">1765.</span>
</pre></div>
</div>
</li>
<li><p><strong>MegaCRN</strong></p>
<p>The paper introduces Spatio-Temporal Meta-Graph Learning for traffic forecasting, proposing a Meta-Graph Convolutional Recurrent Network (MegaCRN) that disentangles spatio-temporal heterogeneity and adapts to non-stationary traffic situations.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Jiang</span> <span class="n">R</span><span class="p">,</span> <span class="n">Wang</span> <span class="n">Z</span><span class="p">,</span> <span class="n">Yong</span> <span class="n">J</span><span class="p">,</span> <span class="n">et</span> <span class="n">al</span><span class="o">.</span> <span class="n">Spatio</span><span class="o">-</span><span class="n">temporal</span> <span class="n">meta</span><span class="o">-</span><span class="n">graph</span> <span class="n">learning</span> <span class="k">for</span> <span class="n">traffic</span> <span class="n">forecasting</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">//</span><span class="n">Proceedings</span> <span class="n">of</span> <span class="n">the</span> <span class="n">AAAI</span> <span class="n">conference</span> <span class="n">on</span> <span class="n">artificial</span> <span class="n">intelligence</span><span class="o">.</span> <span class="mi">2023</span><span class="p">,</span> <span class="mi">37</span><span class="p">(</span><span class="mi">7</span><span class="p">):</span> <span class="mi">8078</span><span class="o">-</span><span class="mf">8086.</span>
</pre></div>
</div>
</li>
<li><p><strong>STAEFormer</strong></p>
<p>The main innovation of the paper is the introduction of a novel component called spatio-temporal adaptive embedding that enables vanilla transformers to achieve state-of-the-art performance in traffic forecasting by effectively capturing intrinsic spatio-temporal relations and chronological information in traffic time series data.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Spatio</span><span class="o">-</span><span class="n">temporal</span> <span class="n">adaptive</span> <span class="n">embedding</span> <span class="n">makes</span> <span class="n">vanilla</span> <span class="n">transformer</span> <span class="n">sota</span> <span class="k">for</span> <span class="n">traffic</span> <span class="n">forecasting</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">//</span><span class="n">Proceedings</span> <span class="n">of</span> <span class="n">the</span> <span class="mi">32</span><span class="n">nd</span> <span class="n">ACM</span> <span class="n">International</span> <span class="n">Conference</span> <span class="n">on</span> <span class="n">Information</span> <span class="ow">and</span> <span class="n">Knowledge</span> <span class="n">Management</span><span class="o">.</span> <span class="mi">2023</span><span class="p">:</span> <span class="mi">4125</span><span class="o">-</span><span class="mf">4129.</span>
</pre></div>
</div>
</li>
<li><p><strong>TESTAM</strong></p>
<p>The main innovation of paper is the proposal of a novel Mixture-of-Experts (MoE) model called TESTAM for traffic forecasting. TESTAM enhances spatio-temporal attention modeling by incorporating three experts with different spatial modeling methods and a gating network for in-situ traffic forecasting. The model is designed to better capture recurring and non-recurring traffic patterns by routing the input through the most suitable expert based on the traffic context.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Lee</span> <span class="n">H</span><span class="p">,</span> <span class="n">Ko</span> <span class="n">S</span><span class="o">.</span> <span class="n">TESTAM</span><span class="p">:</span> <span class="n">A</span> <span class="n">Time</span><span class="o">-</span><span class="n">Enhanced</span> <span class="n">Spatio</span><span class="o">-</span><span class="n">Temporal</span> <span class="n">Attention</span> <span class="n">Model</span> <span class="k">with</span> <span class="n">Mixture</span> <span class="n">of</span> <span class="n">Experts</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">//</span><span class="n">The</span> <span class="n">Twelfth</span> <span class="n">International</span> <span class="n">Conference</span> <span class="n">on</span> <span class="n">Learning</span> <span class="n">Representations</span><span class="o">.</span>
</pre></div>
</div>
</li>
<li><p><strong>Trafformer</strong></p>
<p>This paper unifies spatial and temporal information within a single transformer-style framework to capture complex spatial-temporal dependencies in traffic networks. This design allows for every node at every timestamp to interact with every other node in every other timestamp in a single step, enabling the model to learn intricate relationships that may be missed by existing methods that encode these types of information separately or iteratively. The paper also introduces two variants of Trafformer to improve training and inference speed while maintaining effectiveness. Extensive experiments on two traffic datasets show that Trafformer outperforms existing methods, indicating a promising direction for spatial-temporal traffic prediction.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Jin</span> <span class="n">D</span><span class="p">,</span> <span class="n">Shi</span> <span class="n">J</span><span class="p">,</span> <span class="n">Wang</span> <span class="n">R</span><span class="p">,</span> <span class="n">et</span> <span class="n">al</span><span class="o">.</span> <span class="n">Trafformer</span><span class="p">:</span> <span class="n">unify</span> <span class="n">time</span> <span class="ow">and</span> <span class="n">space</span> <span class="ow">in</span> <span class="n">traffic</span> <span class="n">prediction</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">//</span><span class="n">Proceedings</span> <span class="n">of</span> <span class="n">the</span> <span class="n">AAAI</span> <span class="n">Conference</span> <span class="n">on</span> <span class="n">Artificial</span> <span class="n">Intelligence</span><span class="o">.</span> <span class="mi">2023</span><span class="p">,</span> <span class="mi">37</span><span class="p">(</span><span class="mi">7</span><span class="p">):</span> <span class="mi">8114</span><span class="o">-</span><span class="mf">8122.</span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="on-demand-service-prediction">
<h2>On-Demand Service Prediction<a class="headerlink" href="#on-demand-service-prediction" title="Permalink to this heading"></a></h2>
<ul>
<li><p><strong>DMVSTNET</strong>:</p>
<p>Deep Multi-View Spatial-Temporal Network (DMVST-Net) framework to model both spatial and temporal relations. It consists of three views: temporal view, spatial view, and semantic view.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Huaxiu</span> <span class="n">Yao</span><span class="p">,</span> <span class="n">Fei</span> <span class="n">Wu</span><span class="p">,</span> <span class="n">Jintao</span> <span class="n">Ke</span><span class="p">,</span> <span class="n">Xianfeng</span> <span class="n">Tang</span><span class="p">,</span> <span class="n">Yitian</span> <span class="n">Jia</span><span class="p">,</span> <span class="n">Siyu</span> <span class="n">Lu</span><span class="p">,</span> <span class="n">Pinghua</span> <span class="n">Gong</span><span class="p">,</span> <span class="n">Jieping</span> <span class="n">Ye</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Zhenhui</span> <span class="n">Li</span><span class="o">.</span> <span class="mf">2018.</span> <span class="n">Deep</span> <span class="n">Multi</span><span class="o">-</span><span class="n">View</span> <span class="n">Spatial</span><span class="o">-</span><span class="n">Temporal</span> <span class="n">Network</span> <span class="k">for</span> <span class="n">Taxi</span> <span class="n">Demand</span> <span class="n">Prediction</span><span class="o">.</span> <span class="n">In</span> <span class="n">AAAI</span><span class="o">.</span> <span class="n">AAAI</span> <span class="n">Press</span><span class="p">,</span> <span class="mf">2588.</span>
</pre></div>
</div>
</li>
<li><p><strong>STG2Seq</strong>:</p>
<p>STG2Seq is a model for multistep citywide passenger demand prediction based on a graph and use a hierarchical graph convolutional structure to capture both spatial and temporal correlations simultaneously.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Lei</span> <span class="n">Bai</span><span class="p">,</span> <span class="n">Lina</span> <span class="n">Yao</span><span class="p">,</span> <span class="n">Salil</span> <span class="n">S</span><span class="o">.</span> <span class="n">Kanhere</span><span class="p">,</span> <span class="n">Xianzhi</span> <span class="n">Wang</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Quan</span> <span class="n">Z</span><span class="o">.</span> <span class="n">Sheng</span><span class="o">.</span> <span class="mf">2019.</span> <span class="n">STG2Seq</span><span class="p">:</span> <span class="n">Spatial</span><span class="o">-</span><span class="n">Temporal</span> <span class="n">Graph</span> <span class="n">to</span> <span class="n">Sequence</span> <span class="n">Model</span> <span class="k">for</span> <span class="n">Multi</span><span class="o">-</span><span class="n">step</span> <span class="n">Passenger</span> <span class="n">Demand</span> <span class="n">Forecasting</span><span class="o">.</span> <span class="n">In</span> <span class="n">IJCAI</span><span class="o">.</span> <span class="n">ijcai</span><span class="o">.</span><span class="n">org</span><span class="p">,</span> <span class="mi">1981</span><span class="o">-</span><span class="mf">1987.</span>
</pre></div>
</div>
</li>
<li><p><strong>CCRNN</strong>:</p>
<p>CCRNN is a model to capture multi-level spatial dependence. The adjacency matrices in CGC were self-learned and varied from layer to layer. A layer-wise coupling mechanism was employed to bridge the upper-level graph structure with the lowerlevel one.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Junchen Ye, Leilei Sun, Bowen Du, Yanjie Fu, and Hui Xiong. 2021. Coupled Layer-wise Graph Convolution for Transportation Demand Prediction. In AAAI. AAAI Press, 4617–4625.
</pre></div>
</div>
</li>
</ul>
</section>
<section id="origin-destination-matrix-prediction">
<h2>Origin-Destination Matrix Prediction<a class="headerlink" href="#origin-destination-matrix-prediction" title="Permalink to this heading"></a></h2>
<ul>
<li><p><strong>GEML</strong>:</p>
<p>This model uses the Graph Convolution Neural Network capture space information, P-SKIP LSTM capture time information, and multi-task learning mechanism, predicting every pair of departure - taxi traffic between reaches place</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Yuandong</span> <span class="n">Wang</span><span class="p">,</span> <span class="n">Hongzhi</span> <span class="n">Yin</span><span class="p">,</span> <span class="n">Hongxu</span> <span class="n">Chen</span><span class="p">,</span> <span class="n">Tianyu</span> <span class="n">Wo</span><span class="p">,</span> <span class="n">Jie</span> <span class="n">Xu</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Kai</span> <span class="n">Zheng</span><span class="o">.</span> <span class="mf">2019.</span> <span class="n">Origin</span><span class="o">-</span><span class="n">Destination</span> <span class="n">Matrix</span> <span class="n">Prediction</span> <span class="n">via</span> <span class="n">Graph</span> <span class="n">Convolution</span><span class="p">:</span> <span class="n">a</span> <span class="n">New</span> <span class="n">Perspective</span> <span class="n">of</span> <span class="n">Passenger</span> <span class="n">Demand</span> <span class="n">Modeling</span><span class="o">.</span> <span class="n">In</span> <span class="n">KDD</span><span class="o">.</span> <span class="n">ACM</span><span class="p">,</span> <span class="mi">1227</span><span class="o">-</span><span class="mf">1235.</span>
</pre></div>
</div>
</li>
<li><p><strong>CSTN</strong>:</p>
<p>The model uses a dual view volume of Graph Convolution Neural Network, captures spatial information on the node by the views from the origin and the destination, and uses the convlSTM capture time information, and finally capture global correlations through convolution.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Lingbo</span> <span class="n">Liu</span><span class="p">,</span> <span class="n">Zhilin</span> <span class="n">Qiu</span><span class="p">,</span> <span class="n">Guanbin</span> <span class="n">Li</span><span class="p">,</span> <span class="n">Qing</span> <span class="n">Wang</span><span class="p">,</span> <span class="n">Wanli</span> <span class="n">Ouyang</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Liang</span> <span class="n">Lin</span><span class="o">.</span> <span class="mf">2019.</span> <span class="n">Contextualized</span> <span class="n">Spatial</span><span class="o">-</span><span class="n">Temporal</span> <span class="n">Network</span> <span class="k">for</span> <span class="n">Taxi</span> <span class="n">Origin</span><span class="o">-</span><span class="n">Destination</span> <span class="n">Demand</span> <span class="n">Prediction</span><span class="o">.</span> <span class="n">IEEE</span> <span class="n">Transactions</span> <span class="n">on</span> <span class="n">Intelligent</span> <span class="n">Transportation</span> <span class="n">Systems</span><span class="p">,</span> <span class="mi">20</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="mi">3875</span><span class="o">-</span><span class="mf">3887.</span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="traffic-accidents-prediction">
<h2>Traffic Accidents Prediction<a class="headerlink" href="#traffic-accidents-prediction" title="Permalink to this heading"></a></h2>
<ul>
<li><p><strong>GSNet</strong>:</p>
<p>The model takes spatial-temporal geographical module and spatial-temporal semantic module into account to comprehensively evaluate traffic accident risk and designs a weighted loss function to address the zero-inflated issue, which pays more attention to the samples with high traffic accident risk.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Beibei</span> <span class="n">Wang</span><span class="p">,</span> <span class="n">Youfang</span> <span class="n">Lin</span><span class="p">,</span> <span class="n">Shengnan</span> <span class="n">Guo</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Huaiyu</span> <span class="n">Wan</span><span class="o">.</span> <span class="mf">2021.</span> <span class="n">GSNet</span><span class="p">:</span> <span class="n">Learning</span> <span class="n">Spatial</span><span class="o">-</span><span class="n">Temporal</span> <span class="n">Correlations</span> <span class="kn">from</span> <span class="nn">Geographical</span> <span class="ow">and</span> <span class="n">Semantic</span> <span class="n">Aspects</span> <span class="k">for</span> <span class="n">Traffic</span> <span class="n">Accident</span> <span class="n">Risk</span> <span class="n">Forecasting</span><span class="o">.</span> <span class="n">In</span> <span class="n">AAAI</span><span class="o">.</span> <span class="n">AAAI</span> <span class="n">Press</span><span class="p">,</span> <span class="mi">4402</span><span class="o">-</span><span class="mf">4409.</span> 
</pre></div>
</div>
</li>
</ul>
</section>
<section id="trajectory-next-location-prediction">
<h2>Trajectory Next-Location Prediction<a class="headerlink" href="#trajectory-next-location-prediction" title="Permalink to this heading"></a></h2>
<ul>
<li><p><strong>FPMC</strong>:</p>
<p>This is a classical baseline model of sequence recommendation task. This model is often used as a baseline model in the early research period of trajectory prediction field.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2010. Factorizing Personalized Markov Chains for Next-Basket Recommendation. In WWW. ACM, 811–820.
</pre></div>
</div>
</li>
<li><p><strong>ST-RNN</strong>:
This model focuses on introducing spatiotemporal transfer features into the hidden layer of RNN.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Qiang Liu, Shu Wu, Liang Wang, and Tieniu Tan. 2016. Predicting the Next Location: A Recurrent Model with Spatial and Temporal Contexts. In AAAI. AAAI Press, 194–200.
</pre></div>
</div>
</li>
<li><p><strong>SERM</strong>：</p>
<p>This model introduces the sematic information of the trajectory into the network, which relies on the Glove pretrained word vectors. If you want to run this model, please make sure to download <code class="docutils literal notranslate"><span class="pre">serm_glove_word_vec.zip</span></code> from <a class="reference external" href="https://pan.baidu.com/s/1qEfcXBO-QwZfiT0G3IYMpQ">BaiduDisk with code 1231</a> or <a class="reference external" href="https://drive.google.com/drive/folders/1g5v2Gq1tkOq8XO0HDCZ9nOTtRpB6-gPe?usp=sharing">Google Drive</a> and unzip it to <code class="docutils literal notranslate"><span class="pre">raw_data</span></code> directory.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Di Yao, Chao Zhang, Jian-Hui Huang, and Jingping Bi. 2017. SERM: A Recurrent Model for Next Location Prediction in Semantic Trajectories. In CIKM. ACM, 2411–24.
</pre></div>
</div>
</li>
<li><p><strong>DeepMove</strong>:</p>
<p>This model uses the attention mechanism for the first time to combine historical trajectories with current trajectories for prediction.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Jie Feng, Yong Li, Chao Zhang, Funing Sun, Fanchao Meng, Ang Guo, and Depeng Jin. 2018. DeepMove: Predicting Human Mobility with Attentional Recurrent Networks. In WWW. ACM, 1459–1468.
</pre></div>
</div>
</li>
<li><p><strong>CARA</strong>:</p>
<p>The model focuses on using the attention mechanism to extract contextual information between trajectories for prediction.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Jarana Manotumruksa, Craig Macdonald, and Iadh Ounis. 2018. A Contextual Attention Recurrent Architecture for Context-Aware Venue Recommendation. In SIGIR. ACM, 555–564.
</pre></div>
</div>
</li>
<li><p><strong>HST-LSTM</strong>:</p>
<p>This model also introduces spatio-temporal transfer factors into LSTM, and uses an encoder-decoder structure for prediction.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Dejiang Kong and Fei Wu. 2018. HST-LSTM: A Hierarchical Spatial-Temporal Long-Short Term Memory Network for Location Prediction. In IJCAI. ijcai.org,2341–2347.
</pre></div>
</div>
</li>
<li><p><strong>ATST-LSTM</strong>:</p>
<p>This model introduces the distance difference and time difference between the trajectory points into the LSTM, and uses a Attention mechanism.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Liwei</span> <span class="n">Huang</span><span class="p">,</span> <span class="n">Yutao</span> <span class="n">Ma</span><span class="p">,</span> <span class="n">Shibo</span> <span class="n">Wang</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Yanbo</span> <span class="n">Liu</span><span class="o">.</span> <span class="mf">2019.</span> <span class="n">An</span> <span class="n">Attention</span><span class="o">-</span><span class="n">Based</span> <span class="n">Spatiotemporal</span> <span class="n">LSTM</span> <span class="n">Network</span> <span class="k">for</span> <span class="n">Next</span> <span class="n">POI</span> <span class="n">Recommendation</span><span class="o">.</span> <span class="n">IEEE</span> <span class="n">Transactions</span> <span class="n">on</span> <span class="n">Services</span> <span class="n">Computing</span><span class="p">,</span> <span class="mi">14</span><span class="p">(</span><span class="mi">6</span><span class="p">),</span> <span class="mi">1585</span><span class="o">-</span><span class="mf">1597.</span>
</pre></div>
</div>
</li>
<li><p><strong>LSTPM</strong>:</p>
<p>The model uses two special designed LSTMs to capture the user’s long-term mobile preferences and short-term mobile preferences to jointly predition next location.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Ke</span> <span class="n">Sun</span><span class="p">,</span> <span class="n">Tieyun</span> <span class="n">Qian</span><span class="p">,</span> <span class="n">Tong</span> <span class="n">Chen</span><span class="p">,</span> <span class="n">Yile</span> <span class="n">Liang</span><span class="p">,</span> <span class="n">Quoc</span> <span class="n">Viet</span> <span class="n">Hung</span> <span class="n">Nguyen</span><span class="p">,</span> <span class="ow">and</span> <span class="n">HongzhiYin</span><span class="o">.</span> <span class="mf">2020.</span> <span class="n">Where</span> <span class="n">to</span> <span class="n">Go</span> <span class="n">Next</span><span class="p">:</span> <span class="n">Modeling</span> <span class="n">Long</span><span class="o">-</span> <span class="ow">and</span> <span class="n">Short</span><span class="o">-</span><span class="n">Term</span> <span class="n">User</span> <span class="n">Preferences</span> <span class="k">for</span> <span class="n">Point</span><span class="o">-</span><span class="n">of</span><span class="o">-</span><span class="n">Interest</span> <span class="n">Recommendation</span><span class="o">.</span> <span class="n">In</span> <span class="n">AAAI</span><span class="o">.</span> <span class="n">AAAI</span> <span class="n">Press</span><span class="p">,</span> <span class="mi">214</span><span class="o">-</span><span class="mf">221.</span>
</pre></div>
</div>
</li>
<li><p><strong>GeoSAN</strong>:</p>
<p>The model uses a self-attention mechanism to realize the representation learning of POI, so as to make predictions based on the representation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Defu Lian, Yongji Wu, Yong Ge, Xing Xie, and Enhong Chen. 2020. Geography-Aware Sequential Location Recommendation. In KDD. ACM, 2009–2019.
</pre></div>
</div>
</li>
<li><p><strong>STAN</strong>:</p>
<p>The model uses a self-attention mechanism to capture spatio-temporal information to directly make predictions.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Yingtao</span> <span class="n">Luo</span><span class="p">,</span> <span class="n">Qiang</span> <span class="n">Liu</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Zhaocheng</span> <span class="n">Liu</span><span class="o">.</span> <span class="mf">2021.</span> <span class="n">STAN</span><span class="p">:</span> <span class="n">Spatio</span><span class="o">-</span><span class="n">Temporal</span> <span class="n">Attention</span> <span class="n">Network</span> <span class="k">for</span> <span class="n">Next</span> <span class="n">Location</span> <span class="n">Recommendation</span><span class="o">.</span> <span class="n">In</span> <span class="n">WWW</span><span class="o">.</span> <span class="n">ACM</span><span class="p">,</span> <span class="mi">2177</span><span class="o">-</span><span class="mf">2185.</span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="estimated-time-of-arrival">
<h2>Estimated Time of Arrival<a class="headerlink" href="#estimated-time-of-arrival" title="Permalink to this heading"></a></h2>
<ul>
<li><p><strong>DeepTTE</strong>:</p>
<p>DeepTTE is an end-to-end Deep learning framework for Travel Time Estimation that estimates the travel time of the whole path directly. DeepTTE present a geo-convolution operation by integrating the geographic information into the classical convolution, capable of capturing spatial correlations.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Dong Wang, Junbo Zhang, Wei Cao, Jian Li, and Yu Zheng. 2018. When Will You Arrive? Estimating Travel Time Based on Deep Neural Networks. In AAAI. AAAI Press.
</pre></div>
</div>
</li>
<li><p><strong>TTPNet</strong>:</p>
<p>TTPNet is based on tensor decomposition and graph embedding, which can extract travel speed and representation of road network structure effectively from historical trajectories, as well as predict the travel time with better accuracy.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Yibin</span> <span class="n">Shen</span><span class="p">,</span> <span class="n">Cheqing</span> <span class="n">Jin</span><span class="p">,</span> <span class="n">Jiaxun</span> <span class="n">Hua</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Dingjiang</span> <span class="n">Huang</span><span class="o">.</span> <span class="mf">2020.</span> <span class="n">TTPNet</span><span class="p">:</span> <span class="n">A</span> <span class="n">Neural</span> <span class="n">Network</span> <span class="k">for</span> <span class="n">Travel</span> <span class="n">Time</span> <span class="n">Prediction</span> <span class="n">Based</span> <span class="n">on</span> <span class="n">Tensor</span> <span class="n">Decomposition</span> <span class="ow">and</span> <span class="n">Graph</span> <span class="n">Embedding</span><span class="o">.</span> <span class="n">IEEE</span> <span class="n">Transactions</span> <span class="n">on</span> <span class="n">Knowledge</span> <span class="ow">and</span> <span class="n">Data</span> <span class="n">Engineering</span><span class="p">,</span> <span class="mi">34</span><span class="p">(</span><span class="mi">9</span><span class="p">),</span> <span class="mi">4514</span><span class="o">-</span><span class="mf">4526.</span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="map-matching">
<h2>Map Matching<a class="headerlink" href="#map-matching" title="Permalink to this heading"></a></h2>
<ul>
<li><p><strong>ST-Matching</strong>:</p>
<p>The model considers (1) the spatial geometric and topological structures of the road network and (2) the temporal/speed constraints of the trajectories, and is specially designed for low-sampling-rate GPS trajectories.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Yin Lou, Chengyang Zhang, Yu Zheng, Xing Xie, Wei Wang, and Yan Huang. 2009. Map-Matching for Low-Sampling-Rate GPS Trajectories. In SIGSPATIAL. ACM, 352−361.
</pre></div>
</div>
</li>
<li><p><strong>HMMM</strong>:</p>
<p>The model is a novel, principled map matching algorithm that uses a Hidden Markov Model (HMM) to find the most likely road route represented by a time-stamped sequence of latitude/longitude pairs. The HMM elegantly accounts for measurement noise and the layout of the road network.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Paul</span> <span class="n">Newson</span> <span class="ow">and</span> <span class="n">John</span> <span class="n">Krumm</span><span class="o">.</span> <span class="mf">2009.</span> <span class="n">Hidden</span> <span class="n">Markov</span> <span class="n">Map</span> <span class="n">Matching</span> <span class="n">Through</span> <span class="n">Noise</span> <span class="ow">and</span> <span class="n">Sparseness</span><span class="o">.</span> <span class="n">In</span> <span class="n">SIGSPATIAL</span><span class="o">.</span> <span class="n">ACM</span><span class="p">,</span> <span class="mi">336</span><span class="o">-</span><span class="mf">343.</span>
</pre></div>
</div>
</li>
<li><p><strong>IVMM</strong>:</p>
<p>The model not only considers the spatial and temporal  information of a GPS trajectory but also devises a voting-based strategy to model the weighted mutual influences between GPS  points.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Jing</span> <span class="n">Yuan</span><span class="p">,</span> <span class="n">Yu</span> <span class="n">Zheng</span><span class="p">,</span> <span class="n">Chengyang</span> <span class="n">Zhang</span><span class="p">,</span> <span class="n">Xing</span> <span class="n">Xie</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Guang</span><span class="o">-</span><span class="n">Zhong</span> <span class="n">Sun</span><span class="o">.</span> <span class="mf">2010.</span> <span class="n">An</span> <span class="n">Interactive</span><span class="o">-</span><span class="n">Voting</span> <span class="n">Based</span> <span class="n">Map</span> <span class="n">Matching</span> <span class="n">Algorithm</span><span class="o">.</span> <span class="n">In</span> <span class="n">MDM</span><span class="o">.</span> <span class="n">IEEE</span><span class="p">,</span> <span class="mi">43</span><span class="o">-</span><span class="mf">52.</span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="road-network-representation-learning">
<h2>Road Network Representation Learning<a class="headerlink" href="#road-network-representation-learning" title="Permalink to this heading"></a></h2>
<ul>
<li><p><strong>DeepWalk</strong></p>
<p>A graph structure data mining algorithm combining two algorithms, random walk and Word2Vec</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Bryan</span> <span class="n">Perozzi</span><span class="p">,</span> <span class="n">Rami</span> <span class="n">Al</span><span class="o">-</span><span class="n">Rfou</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Steven</span> <span class="n">Skiena</span><span class="o">.</span> <span class="mf">2014.</span> <span class="n">DeepWalk</span><span class="p">:</span> <span class="n">Online</span> <span class="n">Learning</span> <span class="n">of</span> <span class="n">Social</span> <span class="n">Representations</span><span class="o">.</span> <span class="n">In</span> <span class="n">KDD</span><span class="o">.</span> <span class="n">ACM</span><span class="p">,</span> <span class="mi">701</span><span class="o">-</span><span class="mf">710.</span>
</pre></div>
</div>
</li>
<li><p><strong>LINE</strong></p>
<p>Graph embedding model suitable for large-scale graph structure, considering both first-order and second-order approximations.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Jian</span> <span class="n">Tang</span><span class="p">,</span> <span class="n">Meng</span> <span class="n">Qu</span><span class="p">,</span> <span class="n">Mingzhe</span> <span class="n">Wang</span><span class="p">,</span> <span class="n">Ming</span> <span class="n">Zhang</span><span class="p">,</span> <span class="n">Jun</span> <span class="n">Yan</span><span class="p">,</span> <span class="n">Qiaozhu</span> <span class="n">Mei</span><span class="o">.</span> <span class="mf">2015.</span> <span class="n">LINE</span><span class="p">:</span> <span class="n">Large</span><span class="o">-</span><span class="n">scale</span> <span class="n">Information</span> <span class="n">Network</span> <span class="n">Embedding</span><span class="o">.</span> <span class="n">In</span> <span class="n">WWW</span><span class="o">.</span> <span class="n">ACM</span><span class="p">,</span> <span class="mi">1067</span><span class="o">-</span><span class="mf">1077.</span>
</pre></div>
</div>
</li>
<li><p><strong>ChebConv</strong></p>
<p>The model uses a graph convolution model based on Chebyshev polynomial approximation to calculate the road network representation</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Michaël</span> <span class="n">Defferrard</span><span class="p">,</span> <span class="n">Xavier</span> <span class="n">Bresson</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Pierre</span> <span class="n">Vandergheynst</span><span class="o">.</span> <span class="mf">2016.</span> <span class="n">Convolutional</span> <span class="n">Neural</span> <span class="n">Networks</span> <span class="n">on</span> <span class="n">Graphs</span> <span class="k">with</span> <span class="n">Fast</span> <span class="n">Localized</span> <span class="n">Spectral</span> <span class="n">Filtering</span><span class="o">.</span> <span class="n">In</span> <span class="n">NeurIPS</span><span class="o">.</span>
</pre></div>
</div>
</li>
<li><p><strong>Node2Vec</strong></p>
<p>A graph embedding method that integrates DFS neighborhoods and BFS neighborhoods</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Aditya</span> <span class="n">Grover</span> <span class="ow">and</span> <span class="n">Jure</span> <span class="n">Leskovec</span><span class="o">.</span> <span class="mf">2016.</span> <span class="n">node2vec</span><span class="p">:</span> <span class="n">Scalable</span> <span class="n">Feature</span> <span class="n">Learning</span> <span class="k">for</span> <span class="n">Networks</span><span class="o">.</span> <span class="n">In</span> <span class="n">KDD</span><span class="o">.</span> <span class="n">ACM</span><span class="p">,</span> <span class="mi">855</span><span class="o">-</span><span class="mf">864.</span>
</pre></div>
</div>
</li>
<li><p><strong>GAT</strong></p>
<p>Graph attention networks.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Petar</span> <span class="n">Veličković</span><span class="p">,</span> <span class="n">Guillem</span> <span class="n">Cucurull</span><span class="p">,</span> <span class="n">Arantxa</span> <span class="n">Casanova</span><span class="p">,</span> <span class="n">Adriana</span> <span class="n">Romero</span><span class="p">,</span> <span class="n">Pietro</span> <span class="n">Liò</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Yoshua</span> <span class="n">Bengio</span><span class="o">.</span> <span class="n">Graph</span> <span class="n">Attention</span> <span class="n">Networks</span><span class="o">.</span> <span class="n">In</span> <span class="n">ICLR</span><span class="o">.</span> <span class="n">OpenReview</span><span class="o">.</span><span class="n">net</span><span class="o">.</span>
</pre></div>
</div>
</li>
<li><p><strong>GeomGCN</strong></p>
<p>Geometric graph convolutional networks</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Hongbin</span> <span class="n">Pei</span><span class="p">,</span> <span class="n">Bingzhe</span> <span class="n">Wei</span><span class="p">,</span> <span class="n">Kevin</span> <span class="n">Chen</span><span class="o">-</span><span class="n">Chuan</span> <span class="n">Chang</span><span class="p">,</span> <span class="n">Yu</span> <span class="n">Lei</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Bo</span> <span class="n">Yang</span><span class="o">.</span> <span class="mf">2019.</span> <span class="n">Geom</span><span class="o">-</span><span class="n">GCN</span><span class="p">:</span> <span class="n">Geometric</span> <span class="n">Graph</span> <span class="n">Convolutional</span> <span class="n">Networks</span><span class="o">.</span> <span class="n">In</span> <span class="n">ICLR</span><span class="o">.</span> <span class="n">OpenReview</span><span class="o">.</span><span class="n">net</span><span class="o">.</span>
</pre></div>
</div>
</li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="data/dataset_for_task.html" class="btn btn-neutral float-left" title="Dataset For Task" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="evaluator.html" class="btn btn-neutral float-right" title="Evaluator Introduction" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, aptx1231.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>